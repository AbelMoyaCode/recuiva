"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TEST_CHUNKING.PY - Pruebas Unitarias del MÃ³dulo de Chunking
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Este mÃ³dulo contiene las pruebas unitarias para verificar:
1. ExtracciÃ³n de texto desde PDFs
2. DivisiÃ³n semÃ¡ntica del texto en chunks
3. ParÃ¡metros de chunking (min_words, max_words, overlap)
4. Manejo de diferentes formatos de entrada
5. Calidad de los chunks generados

MÃ©todos de extracciÃ³n probados:
- pdftotext
- PyMuPDF (fitz)
- PyPDF2
- Tesseract OCR (fallback)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import pytest
import sys
import os
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock

# Agregar backend al path
BACKEND_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(BACKEND_DIR))

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLASE: TestSemanticChunking - Pruebas de divisiÃ³n semÃ¡ntica
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TestSemanticChunking:
    """
    Pruebas de la funciÃ³n semantic_chunking()
    
    Esta funciÃ³n divide el texto en fragmentos semÃ¡nticamente coherentes
    respetando los lÃ­mites configurados.
    """
    
    def test_chunking_returns_list(self):
        """
        TEST: semantic_chunking() debe retornar una lista
        """
        from chunking import semantic_chunking
        
        texto = "Un puntero es una variable. Almacena direcciones de memoria."
        chunks = semantic_chunking(texto)
        
        assert isinstance(chunks, list), f"Debe retornar list, obtenido: {type(chunks)}"
        print(f"âœ… Retorna lista con {len(chunks)} chunks")
    
    def test_chunking_respects_min_words(self):
        """
        TEST: Los chunks deben tener al menos min_words palabras
        """
        from chunking import semantic_chunking
        
        texto = """
        Los punteros son variables especiales que almacenan direcciones de memoria.
        En C++, se declaran usando el operador asterisco.
        La desreferenciaciÃ³n permite acceder al valor almacenado.
        Los punteros nulos apuntan a la direcciÃ³n cero.
        """
        
        min_words = 10
        chunks = semantic_chunking(texto, min_words=min_words, max_words=50)
        
        for i, chunk in enumerate(chunks):
            if chunk.strip():
                word_count = len(chunk.split())
                # Permitir cierta flexibilidad en los bordes
                assert word_count >= min_words * 0.5 or len(chunks) == 1, \
                    f"Chunk {i} tiene {word_count} palabras, mÃ­nimo esperado: {min_words}"
        
        print(f"âœ… Todos los chunks respetan min_words={min_words}")
    
    def test_chunking_respects_max_words(self):
        """
        TEST: Los chunks no deben exceder max_words palabras
        """
        from chunking import semantic_chunking
        
        # Texto mÃ¡s realista con oraciones completas
        texto = """
        Los punteros son variables especiales que almacenan direcciones de memoria.
        En C++ se utilizan para acceso directo a la memoria del sistema operativo.
        La declaraciÃ³n de un puntero se realiza usando el operador asterisco.
        Para obtener la direcciÃ³n de una variable se usa el operador ampersand.
        La desreferenciaciÃ³n permite acceder al valor almacenado en la direcciÃ³n.
        Los punteros nulos apuntan a la direcciÃ³n cero y no son vÃ¡lidos.
        """ * 5  # Repetir para tener texto largo
        
        max_words = 80
        
        chunks = semantic_chunking(texto, min_words=20, max_words=max_words)
        
        # Verificar que hay mÃºltiples chunks
        assert len(chunks) >= 1, "Debe generar al menos un chunk"
        
        # La mayorÃ­a de chunks deben respetar el lÃ­mite (permitir excepciones)
        chunks_dentro_limite = sum(1 for c in chunks if len(c.split()) <= max_words * 1.5)
        porcentaje = chunks_dentro_limite / len(chunks) if chunks else 0
        
        assert porcentaje >= 0.5, f"Al menos 50% de chunks deben respetar max_words"
        
        print(f"âœ… {chunks_dentro_limite}/{len(chunks)} chunks respetan max_words={max_words}")
    
    def test_chunking_with_overlap(self):
        """
        TEST: Los chunks deben tener overlap para contexto
        """
        from chunking import semantic_chunking
        
        texto = """
        Concepto uno sobre punteros y variables en programaciÃ³n.
        Concepto dos sobre memoria y direcciones del sistema.
        Concepto tres sobre declaraciÃ³n y uso de punteros.
        Concepto cuatro sobre desreferenciaciÃ³n de variables.
        """
        
        overlap_words = 5
        chunks = semantic_chunking(texto, min_words=10, max_words=30, overlap_words=overlap_words)
        
        if len(chunks) > 1:
            # Verificar que hay algÃºn texto compartido entre chunks consecutivos
            # (El overlap puede no ser exactamente las mismas palabras debido a la divisiÃ³n semÃ¡ntica)
            print(f"âœ… Generados {len(chunks)} chunks con overlap_words={overlap_words}")
        else:
            print(f"âœ… Texto muy corto, solo 1 chunk generado")
    
    def test_empty_text_handling(self):
        """
        TEST: semantic_chunking() debe manejar texto vacÃ­o
        """
        from chunking import semantic_chunking
        
        try:
            chunks = semantic_chunking("")
            assert chunks == [] or chunks == [""], "Texto vacÃ­o debe retornar lista vacÃ­a o con string vacÃ­o"
            print(f"âœ… Texto vacÃ­o manejado correctamente: {chunks}")
        except Exception as e:
            print(f"âœ… Texto vacÃ­o genera excepciÃ³n controlada: {type(e).__name__}")
    
    def test_whitespace_only_text(self):
        """
        TEST: Texto con solo espacios debe manejarse correctamente
        """
        from chunking import semantic_chunking
        
        try:
            chunks = semantic_chunking("   \n\t   ")
            print(f"âœ… Texto con espacios manejado: {len(chunks)} chunks")
        except Exception as e:
            print(f"âœ… Texto con espacios genera excepciÃ³n controlada: {type(e).__name__}")
    
    def test_spanish_text_with_accents(self):
        """
        TEST: El chunking debe funcionar con texto en espaÃ±ol
        """
        from chunking import semantic_chunking
        
        texto_espanol = """
        La programaciÃ³n orientada a objetos utiliza clases y mÃ©todos.
        Los algoritmos de bÃºsqueda son fundamentales en ciencias de la computaciÃ³n.
        La recursiÃ³n permite resolver problemas dividiÃ©ndolos en subproblemas mÃ¡s pequeÃ±os.
        """
        
        chunks = semantic_chunking(texto_espanol, min_words=10, max_words=50)
        
        assert len(chunks) > 0, "Debe generar al menos un chunk"
        # Verificar que los acentos se preservan
        texto_completo = " ".join(chunks)
        assert "programaciÃ³n" in texto_completo or "computaciÃ³n" in texto_completo, \
            "Los acentos deben preservarse"
        
        print(f"âœ… Texto espaÃ±ol procesado: {len(chunks)} chunks")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLASE: TestPDFExtraction - Pruebas de extracciÃ³n de PDF
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TestPDFExtraction:
    """
    Pruebas de extracciÃ³n de texto desde PDFs
    
    MÃ©todos disponibles:
    - pdftotext (lÃ­nea de comandos)
    - PyMuPDF (fitz)
    - PyPDF2
    - Tesseract OCR (fallback)
    """
    
    def test_extract_text_function_exists(self):
        """
        TEST: La funciÃ³n extract_text_from_pdf debe existir
        """
        from chunking import extract_text_from_pdf
        
        assert callable(extract_text_from_pdf), "extract_text_from_pdf debe ser una funciÃ³n"
        print(f"âœ… FunciÃ³n extract_text_from_pdf disponible")
    
    def test_extraction_with_invalid_path(self):
        """
        TEST: Debe manejar rutas de archivo invÃ¡lidas
        """
        from chunking import extract_text_from_pdf
        
        try:
            result = extract_text_from_pdf("/ruta/invalida/archivo.pdf")
            # Puede retornar None, string vacÃ­o, o lanzar excepciÃ³n
            print(f"âœ… Ruta invÃ¡lida manejada: {type(result)}")
        except (FileNotFoundError, Exception) as e:
            print(f"âœ… Ruta invÃ¡lida genera excepciÃ³n controlada: {type(e).__name__}")
    
    def test_extraction_methods_available(self):
        """
        TEST: Verificar quÃ© mÃ©todos de extracciÃ³n estÃ¡n disponibles
        """
        available_methods = []
        
        # Verificar PyMuPDF
        try:
            import fitz
            available_methods.append("PyMuPDF (fitz)")
        except ImportError:
            pass
        
        # Verificar PyPDF2
        try:
            import PyPDF2
            available_methods.append("PyPDF2")
        except ImportError:
            pass
        
        # Verificar pdftotext (difÃ­cil de verificar sin ejecutar)
        available_methods.append("pdftotext (si estÃ¡ instalado)")
        
        print(f"ğŸ“Š MÃ©todos de extracciÃ³n disponibles:")
        for method in available_methods:
            print(f"   âœ“ {method}")
        
        assert len(available_methods) >= 1, "Debe haber al menos un mÃ©todo de extracciÃ³n"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLASE: TestAdaptiveChunking - Pruebas de chunking adaptativo
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TestAdaptiveChunking:
    """
    Pruebas del chunking adaptativo
    
    El chunking adaptativo ajusta los parÃ¡metros segÃºn
    las caracterÃ­sticas del documento.
    """
    
    def test_adaptive_chunking_exists(self):
        """
        TEST: Verificar que existe funciÃ³n de chunking adaptativo
        """
        try:
            from chunking import adaptive_chunking
            assert callable(adaptive_chunking)
            print(f"âœ… FunciÃ³n adaptive_chunking disponible")
        except ImportError:
            pytest.skip("adaptive_chunking no implementado")
    
    def test_short_text_fewer_chunks(self):
        """
        TEST: Texto corto debe generar pocos chunks
        """
        from chunking import semantic_chunking
        
        texto_corto = "Un puntero almacena direcciones."
        texto_largo = texto_corto * 20
        
        chunks_corto = semantic_chunking(texto_corto, min_words=5, max_words=50)
        chunks_largo = semantic_chunking(texto_largo, min_words=5, max_words=50)
        
        assert len(chunks_corto) <= len(chunks_largo), \
            "Texto corto debe generar <= chunks que texto largo"
        
        print(f"âœ… Texto corto: {len(chunks_corto)} chunks, Texto largo: {len(chunks_largo)} chunks")
    
    def test_chunks_preserve_sentence_boundaries(self):
        """
        TEST: Los chunks deben respetar lÃ­mites de oraciones cuando sea posible
        """
        from chunking import semantic_chunking
        
        texto = """
        Primera oraciÃ³n completa sobre punteros.
        Segunda oraciÃ³n sobre memoria y variables.
        Tercera oraciÃ³n sobre declaraciones en C++.
        """
        
        chunks = semantic_chunking(texto, min_words=5, max_words=20)
        
        # Verificar que los chunks terminan con puntuaciÃ³n o son coherentes
        for chunk in chunks:
            chunk = chunk.strip()
            if chunk:
                # El chunk debe ser texto legible
                assert len(chunk) > 0, "Chunk no debe estar vacÃ­o"
        
        print(f"âœ… Chunks generados respetan estructura del texto")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLASE: TestChunkQuality - Pruebas de calidad de chunks
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TestChunkQuality:
    """
    Pruebas de calidad de los chunks generados
    
    Los chunks deben ser:
    - SemÃ¡nticamente coherentes
    - No demasiado cortos ni largos
    - Ãštiles para embeddings
    """
    
    def test_chunks_are_not_empty(self, material_punteros):
        """
        TEST: Los chunks no deben estar vacÃ­os
        """
        from chunking import semantic_chunking
        
        chunks = semantic_chunking(material_punteros, min_words=10, max_words=50)
        
        empty_chunks = [c for c in chunks if not c.strip()]
        non_empty_chunks = [c for c in chunks if c.strip()]
        
        # Permitir algunos chunks vacÃ­os pero la mayorÃ­a deben tener contenido
        assert len(non_empty_chunks) > len(empty_chunks), \
            f"Demasiados chunks vacÃ­os: {len(empty_chunks)}/{len(chunks)}"
        
        print(f"âœ… {len(non_empty_chunks)} chunks con contenido, {len(empty_chunks)} vacÃ­os")
    
    def test_chunks_contain_meaningful_content(self, material_punteros):
        """
        TEST: Los chunks deben contener contenido significativo
        """
        from chunking import semantic_chunking
        
        chunks = semantic_chunking(material_punteros, min_words=10, max_words=50)
        
        # Palabras clave que deberÃ­an aparecer en los chunks
        keywords = ["puntero", "memoria", "variable", "direcciÃ³n"]
        
        keywords_found = set()
        for chunk in chunks:
            chunk_lower = chunk.lower()
            for kw in keywords:
                if kw in chunk_lower:
                    keywords_found.add(kw)
        
        # Al menos algunas keywords deben estar presentes
        assert len(keywords_found) >= 2, \
            f"Solo se encontraron {len(keywords_found)} keywords: {keywords_found}"
        
        print(f"âœ… Keywords encontradas: {keywords_found}")
    
    def test_chunk_length_distribution(self, material_punteros):
        """
        TEST: La distribuciÃ³n de longitud de chunks debe ser razonable
        """
        from chunking import semantic_chunking
        
        chunks = semantic_chunking(material_punteros, min_words=20, max_words=60)
        
        lengths = [len(c.split()) for c in chunks if c.strip()]
        
        if lengths:
            avg_length = sum(lengths) / len(lengths)
            min_length = min(lengths)
            max_length = max(lengths)
            
            print(f"ğŸ“Š DistribuciÃ³n de longitud de chunks:")
            print(f"   MÃ­nimo: {min_length} palabras")
            print(f"   MÃ¡ximo: {max_length} palabras")
            print(f"   Promedio: {avg_length:.1f} palabras")
            print(f"   Total chunks: {len(lengths)}")
            
            # La variaciÃ³n no debe ser extrema
            assert max_length <= avg_length * 3, "VariaciÃ³n de longitud muy alta"
        
        print(f"âœ… DistribuciÃ³n de longitud dentro de parÃ¡metros")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLASE: TestChunkingConfiguration - Pruebas de configuraciÃ³n
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TestChunkingConfiguration:
    """
    Pruebas de diferentes configuraciones de chunking
    """
    
    def test_default_parameters(self):
        """
        TEST: Verificar parÃ¡metros por defecto
        """
        from chunking import semantic_chunking
        import inspect
        
        sig = inspect.signature(semantic_chunking)
        
        print(f"ğŸ“Š ParÃ¡metros de semantic_chunking:")
        for name, param in sig.parameters.items():
            default = param.default if param.default != inspect.Parameter.empty else "requerido"
            print(f"   {name}: {default}")
        
        print(f"âœ… ConfiguraciÃ³n de parÃ¡metros verificada")
    
    def test_custom_parameters(self):
        """
        TEST: Chunking con parÃ¡metros personalizados
        """
        from chunking import semantic_chunking
        
        texto = "Texto de prueba. " * 50
        
        # Probar diferentes configuraciones
        configs = [
            {"min_words": 10, "max_words": 30},
            {"min_words": 20, "max_words": 60},
            {"min_words": 30, "max_words": 100},
        ]
        
        for config in configs:
            chunks = semantic_chunking(texto, **config)
            print(f"   Config {config}: {len(chunks)} chunks")
        
        print(f"âœ… ParÃ¡metros personalizados funcionan correctamente")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TESTS INDIVIDUALES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_chunking_import():
    """Test rÃ¡pido de importaciÃ³n"""
    from chunking import semantic_chunking
    assert semantic_chunking is not None


def test_basic_chunking():
    """Test bÃ¡sico de chunking"""
    from chunking import semantic_chunking
    
    texto = "Este es un texto de prueba. Contiene varias oraciones. Para verificar el chunking."
    chunks = semantic_chunking(texto, min_words=5, max_words=20)
    
    assert isinstance(chunks, list)
    assert len(chunks) >= 1


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])
