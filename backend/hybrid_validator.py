import numpy as np
import re
from typing import List, Dict, Tuple
from rank_bm25 import BM25Okapi

class HybridValidator:
    def __init__(self, embedding_model):
        self.model = embedding_model
        # Umbrales para clasificaciÃ³n de respuestas (basados en Short Answer Grading - SAG)
        # Estos umbrales se aplican sobre S_raw (score bruto en [0,1])
        self.thresholds = {
            'excelente': 0.85,   # â‰¥0.85 â†’ Excelente (90-100%)
            'bueno': 0.70,       # 0.70-0.84 â†’ Bueno (70-89%)
            'aceptable': 0.50,   # 0.50-0.69 â†’ Aceptable (50-69%)
            'rechazo': 0.50      # <0.50 â†’ Necesita mejorar (0-49%)
        }
        # Pesos optimizados para OCR + parafraseo (basado en literatura SAG)
        # Priorizan semÃ¡ntica sobre lÃ©xico por errores OCR en PDFs
        self.weights = {
            'bm25': 0.05,        # 5% - Coincidencias lÃ©xicas (reducido por OCR)
            'cosine': 0.80,      # 80% - Similitud semÃ¡ntica (eje principal)
            'coverage': 0.15     # 15% - Cobertura de keywords clave
        }
        # Rango de normalizaciÃ³n para cosine similarity (valores empÃ­ricos)
        # AJUSTADO: Para PDFs con texto corrupto/OCR, los cosines son mÃ¡s bajos
        # Basado en all-MiniLM-L6-v2 + anÃ¡lisis de respuestas reales
        self.cosine_min = 0.25   # Por debajo: casi siempre incorrecto (antes: 0.30)
        self.cosine_max = 0.70   # Por encima: muy similar al texto (antes: 0.80)
        
        # Min-max scaling para porcentaje 0-100%
        # AJUSTADO: MÃ¡s tolerante para texto con errores de espaciado
        self.expected_min = 0.25  # Respuesta muy mala â†’ 0% (antes: 0.30)
        self.expected_max = 0.85  # Respuesta excelente â†’ 100% (antes: 0.90)
        
        self.stopwords = {'el', 'la', 'los', 'las', 'un', 'una', 'de', 'del', 'a', 'al', 'en', 'por', 'para', 'con', 'y', 'o', 'pero', 'si', 'no', 'que', 'como', 'cuando', 'donde', 'cual', 'quien', 'su', 'sus', 'mi', 'mis', 'tu', 'tus', 'se', 'le', 'lo', 'me', 'te', 'nos', 'os'}
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # VERBOS DE RAZONAMIENTO (para compute_reasoning_score)
        # Verbos que indican pensamiento, opiniÃ³n, deducciÃ³n, etc.
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        self.reasoning_verbs = [
            # Verbos de pensamiento
            'pensÃ³', 'pensaba', 'piensa', 'pensar', 'pensando',
            'creyÃ³', 'creÃ­a', 'cree', 'creer', 'creyendo',
            'supuso', 'suponÃ­a', 'supone', 'suponer', 'suponiendo',
            'imaginÃ³', 'imaginaba', 'imagina', 'imaginar', 'imaginando',
            
            # Verbos de deducciÃ³n/conclusiÃ³n
            'dedujo', 'deducÃ­a', 'deduce', 'deducir', 'deduciendo',
            'concluyÃ³', 'concluÃ­a', 'concluye', 'concluir', 'concluyendo',
            'infiriÃ³', 'inferÃ­a', 'infiere', 'inferir', 'infiriendo',
            'razonÃ³', 'razonaba', 'razona', 'razonar', 'razonando',
            
            # Verbos de sospecha/duda
            'sospechÃ³', 'sospechaba', 'sospecha', 'sospechar', 'sospechando',
            'dudÃ³', 'dudaba', 'duda', 'dudar', 'dudando',
            'desconfiÃ³', 'desconfiaba', 'desconfÃ­a', 'desconfiar',
            
            # Verbos de decisiÃ³n/juicio
            'decidiÃ³', 'decidÃ­a', 'decide', 'decidir', 'decidiendo',
            'juzgÃ³', 'juzgaba', 'juzga', 'juzgar', 'juzgando',
            'opinÃ³', 'opinaba', 'opina', 'opinar', 'opinando',
            'considerÃ³', 'consideraba', 'considera', 'considerar',
            
            # Verbos de comprensiÃ³n
            'comprendiÃ³', 'comprendÃ­a', 'comprende', 'comprender',
            'entendiÃ³', 'entendÃ­a', 'entiende', 'entender',
            'advirtiÃ³', 'advertÃ­a', 'advierte', 'advertir',
            'notÃ³', 'notaba', 'nota', 'notar',
            'percibiÃ³', 'percibÃ­a', 'percibe', 'percibir',
            
            # Verbos de intenciÃ³n
            'pretendiÃ³', 'pretendÃ­a', 'pretende', 'pretender',
            'intentÃ³', 'intentaba', 'intenta', 'intentar',
            'quiso', 'querÃ­a', 'quiere', 'querer',
            'buscÃ³', 'buscaba', 'busca', 'buscar',
            
            # Verbos de reflexiÃ³n
            'reflexionÃ³', 'reflexionaba', 'reflexiona', 'reflexionar',
            'meditÃ³', 'meditaba', 'medita', 'meditar',
            'analizÃ³', 'analizaba', 'analiza', 'analizar',
        ]
        
        # Caracteres que indican diÃ¡logo
        self.dialogue_chars = ['"', 'Â«', 'Â»', 'â€”', '-', '"', '"', ''', ''']
    
    def classify_question_type(self, question: str) -> str:
        """
        Clasifica el tipo de pregunta: 'reasoning', 'literal', u 'other'.
        
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        BASADO EN: TaxonomÃ­a de Bloom + Reading Comprehension Research
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        RAZONAMIENTO/INFERENCIAL:
        - Preguntas que requieren deducir, inferir, explicar motivos
        - "Â¿Por quÃ©...?", "Â¿QuÃ© proceso de pensamiento...?", "Â¿QuÃ© intenciÃ³n...?"
        
        LITERAL/HECHO:
        - Preguntas sobre informaciÃ³n explÃ­cita en el texto
        - "Â¿QuÃ© hizo...?", "Â¿DÃ³nde estaba...?", "Â¿CuÃ¡ndo...?"
        
        Args:
            question: Texto de la pregunta
            
        Returns:
            str: 'reasoning', 'literal', u 'other'
        """
        question_lower = question.lower()
        
        # Patrones para preguntas de RAZONAMIENTO
        reasoning_patterns = [
            # Causales
            'por quÃ©', 'por que', 'cuÃ¡l es la razÃ³n', 'cual es la razon',
            'quÃ© razones', 'que razones', 'quÃ© motivo', 'que motivo',
            'a quÃ© se debe', 'a que se debe', 'cÃ³mo se explica', 'como se explica',
            
            # Procesos mentales
            'quÃ© proceso de pensamiento', 'que proceso de pensamiento',
            'quÃ© pensÃ³', 'que penso', 'quÃ© opiniÃ³n', 'que opinion',
            'quÃ© postura', 'que postura', 'cÃ³mo interpreta', 'como interpreta',
            'quÃ© intenciÃ³n', 'que intencion', 'con quÃ© propÃ³sito', 'con que proposito',
            
            # Inferencia
            'quÃ© sugiere', 'que sugiere', 'quÃ© indica', 'que indica',
            'quÃ© permite deducir', 'que permite deducir', 'quÃ© implica', 'que implica',
            'quÃ© se puede inferir', 'que se puede inferir',
            'quÃ© conclusiÃ³n', 'que conclusion',
            
            # Significado
            'quÃ© representa', 'que representa', 'quÃ© simboliza', 'que simboliza',
            'quÃ© significa', 'que significa', 'cuÃ¡l es el significado',
            'quÃ© importancia tiene', 'que importancia tiene',
        ]
        
        # Patrones para preguntas LITERALES
        literal_patterns = [
            # Hechos directos
            'quÃ© hizo', 'que hizo', 'quÃ© dijo', 'que dijo',
            'dÃ³nde estaba', 'donde estaba', 'dÃ³nde se encontraba', 'donde se encontraba',
            'cuÃ¡ndo ocurriÃ³', 'cuando ocurrio', 'cuÃ¡ndo sucediÃ³', 'cuando sucedio',
            'quiÃ©n era', 'quien era', 'quiÃ©nes eran', 'quienes eran',
            
            # Relaciones/Datos
            'quÃ© relaciÃ³n tenÃ­a', 'que relacion tenia', 'quÃ© recibÃ­a', 'que recibia',
            'quÃ© papel cumple', 'que papel cumple', 'cuÃ¡ntos', 'cuantos',
            'quÃ© tipo de', 'que tipo de', 'cuÃ¡l era', 'cual era',
            
            # Descripciones
            'cÃ³mo era', 'como era', 'cÃ³mo se llamaba', 'como se llamaba',
            'quÃ© contenÃ­a', 'que contenia', 'quÃ© incluÃ­a', 'que incluia',
        ]
        
        # Verificar patrones de razonamiento primero
        for pattern in reasoning_patterns:
            if pattern in question_lower:
                return 'reasoning'
        
        # Verificar patrones literales
        for pattern in literal_patterns:
            if pattern in question_lower:
                return 'literal'
        
        # Por defecto
        return 'other'
    
    def compute_reasoning_score(self, chunk_text: str) -> float:
        """
        Calcula un score de "razonamiento" para un chunk [0, 1].
        
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        PROPÃ“SITO:
        Para preguntas de razonamiento/inferenciales, priorizar chunks
        que contengan mÃ¡s diÃ¡logo y verbos de pensamiento/opiniÃ³n.
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        COMPONENTES:
        1. dialogue_ratio: ProporciÃ³n de caracteres de diÃ¡logo
        2. reasoning_verbs_ratio: Densidad de verbos de razonamiento
        
        FÃ“RMULA:
        score = 0.6 * dialogue_ratio + 0.4 * reasoning_verbs_normalized
        
        Args:
            chunk_text: Texto del chunk
            
        Returns:
            float: Score en [0, 1]
        """
        if not chunk_text or len(chunk_text) < 10:
            return 0.0
        
        chunk_lower = chunk_text.lower()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 1. RATIO DE DIÃLOGO
        # ProporciÃ³n de caracteres que son marcadores de diÃ¡logo
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        dialogue_count = sum(chunk_text.count(char) for char in self.dialogue_chars)
        dialogue_ratio = min(1.0, dialogue_count / (len(chunk_text) * 0.05))  # Normalizar
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 2. RATIO DE VERBOS DE RAZONAMIENTO
        # Contar apariciones de verbos de pensamiento/opiniÃ³n
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        words = chunk_lower.split()
        word_count = max(len(words), 1)
        
        reasoning_count = 0
        for verb in self.reasoning_verbs:
            reasoning_count += chunk_lower.count(verb)
        
        # Normalizar: esperamos ~1-3 verbos de razonamiento por cada 100 palabras
        reasoning_ratio = min(1.0, (reasoning_count / word_count) * 50)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # COMBINAR: 60% diÃ¡logo + 40% verbos de razonamiento
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        score = 0.6 * dialogue_ratio + 0.4 * reasoning_ratio
        
        return max(0.0, min(1.0, score))
    
    def normalize_cosine(self, cosine_sim: float) -> float:
        """
        Normaliza similitud del coseno al rango 0-1 usando lÃ­mites empÃ­ricos
        
        Basado en investigaciÃ³n de Sentence-BERT:
        - cosine < 0.30: sin relaciÃ³n (0%)
        - cosine = 0.80: muy similar (100%)
        
        Referencia: Reimers & Gurevych (2019), "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"
        """
        normalized = (cosine_sim - self.cosine_min) / (self.cosine_max - self.cosine_min)
        return max(0.0, min(1.0, normalized))  # Clamp a [0, 1]
    
    def length_bonus(self, answer: str) -> float:
        """
        Bonus pequeÃ±o por respuestas de longitud razonable
        Evita respuestas telegrama o testamentos
        
        Args:
            answer: Texto de la respuesta del alumno
            
        Returns:
            float: Bonus en [0, 0.05] (mÃ¡ximo 5 puntos extra)
        """
        tokens = len(answer.split())
        if 8 <= tokens <= 80:  # Rango razonable para Active Recall
            return 0.05
        return 0.0
    
    def to_percentage(self, score_raw: float) -> float:
        """
        Convierte score bruto [0,1] a porcentaje 0-100% con min-max scaling
        
        Mapea el rango esperado de scores reales [0.30-0.90] a [0-100%]
        para distribuir mejor los resultados en toda la escala.
        
        Args:
            score_raw: Score bruto en [0,1]
            
        Returns:
            float: Porcentaje en [0.0, 100.0]
        """
        scaled = (score_raw - self.expected_min) / (self.expected_max - self.expected_min)
        scaled = max(0.0, min(1.0, scaled))  # Clamp a [0,1]
        return round(scaled * 100, 1)
    
    def is_inferential_question(self, question: str) -> bool:
        """
        Detecta si una pregunta es inferencial por palabras clave.
        
        BASADO EN: TaxonomÃ­a de Bloom + InvestigaciÃ³n en Reading Comprehension
        
        NIVELES DE COMPRENSIÃ“N (Barrett, 1968; Bloom, 1956):
        
        1. LITERAL: Recordar informaciÃ³n explÃ­cita del texto
           - "Â¿QuiÃ©n...?", "Â¿CuÃ¡ndo...?", "Â¿DÃ³nde...?", "Â¿QuÃ© dijo...?"
           
        2. INFERENCIAL: Deducir informaciÃ³n implÃ­cita
           - "Â¿Por quÃ©...?", "Â¿QuÃ© sugiere...?", "Â¿CÃ³mo se explica...?"
           
        3. CRÃTICO/EVALUATIVO: Juzgar y valorar
           - "Â¿QuÃ© opinas...?", "Â¿EstÃ¡s de acuerdo...?"
        
        Las preguntas inferenciales requieren que el lector:
        - Conecte informaciÃ³n de diferentes partes del texto
        - Use conocimiento previo + informaciÃ³n del texto
        - Haga deducciones lÃ³gicas
        
        Referencia: Education Endowment Foundation (2025), 
        "Reading Comprehension Strategies" - Making inferences
        
        Args:
            question: Texto de la pregunta
            
        Returns:
            bool: True si es inferencial, False si es literal
        """
        # Keywords para preguntas INFERENCIALES (requieren razonamiento)
        inferential_keywords = [
            # Causales - "Â¿Por quÃ©?"
            'por quÃ©', 'por que', 'cuÃ¡l es la razÃ³n', 'cual es la razon',
            'quÃ© razones', 'que razones', 'quÃ© motivo', 'que motivo',
            'a quÃ© se debe', 'a que se debe', 'cÃ³mo se explica', 'como se explica',
            
            # Inferenciales - DeducciÃ³n
            'quÃ© sugiere', 'que sugiere', 'quÃ© indica', 'que indica',
            'quÃ© permite deducir', 'que permite deducir', 'quÃ© implica', 'que implica',
            'quÃ© evidencia', 'que evidencia', 'quÃ© indicio', 'que indicio',
            'cÃ³mo deduce', 'como deduce', 'cÃ³mo sabes', 'como sabes',
            'quÃ© puedes inferir', 'que puedes inferir',
            'quÃ© conclusiÃ³n', 'que conclusion',
            
            # Predictivas
            'quÃ© pasarÃ­a si', 'que pasaria si', 'quÃ© crees que', 'que crees que',
            'quÃ© hubiera pasado', 'que hubiera pasado',
            
            # Comparativas/AnalÃ­ticas
            'en quÃ© se diferencia', 'en que se diferencia',
            'quÃ© relaciÃ³n', 'que relacion', 'cÃ³mo se relaciona', 'como se relaciona',
            'quÃ© tienen en comÃºn', 'que tienen en comun',
            
            # Intenciones/PropÃ³sito
            'con quÃ© intenciÃ³n', 'con que intencion',
            'para quÃ©', 'para que', 'cuÃ¡l es el propÃ³sito', 'cual es el proposito',
            'quÃ© pretende', 'que pretende',
            
            # Significado/Simbolismo (NUEVO)
            'quÃ© representa', 'que representa', 'quÃ© simboliza', 'que simboliza',
            'quÃ© significa', 'que significa', 'cuÃ¡l es el significado', 'cual es el significado',
            'quÃ© importancia', 'que importancia', 'cuÃ¡l es la importancia', 'cual es la importancia',
            'quÃ© papel', 'que papel', 'quÃ© rol', 'que rol',
            'quÃ© sentido', 'que sentido'
        ]
        
        question_lower = question.lower()
        return any(keyword in question_lower for keyword in inferential_keywords)
    
    def detect_contradiction(self, user_answer: str, chunk_text: str, question: str = "") -> Tuple[bool, float, str]:
        """
        Detecta si la respuesta del usuario CONTRADICE el contenido del chunk.
        
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        PROBLEMA IDENTIFICADO (Testing con GPT):
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        Ejemplo de fallo sin esta funciÃ³n:
        - Chunk dice: "Henriette recibÃ­a dinero cada aÃ±o por correo"
        - Usuario responde: "La condesa nunca le mandÃ³ dinero"
        - Sin NLI: score alto (78%) porque comparte palabras como "dinero", "correo"
        - Con NLI: deberÃ­a ser RECHAZO (<50%)
        
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ESTRATEGIA DE DETECCIÃ“N:
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        1. Identificar KEYWORDS CLAVE del chunk (sustantivos importantes)
        2. Buscar patrones de NEGACIÃ“N en la respuesta del usuario
        3. Si encuentra negaciÃ³n de keyword clave â†’ CONTRADICCIÃ“N
        
        Patrones de negaciÃ³n:
        - "no [keyword]", "nunca [keyword]", "sin [keyword]"
        - "jamÃ¡s", "ningÃºn/ninguna", "nada de"
        
        Args:
            user_answer: Respuesta del usuario
            chunk_text: Texto del chunk de referencia
            question: Pregunta original (para contexto)
            
        Returns:
            Tuple[bool, float, str]: (is_contradiction, penalty_factor, reason)
        """
        answer_lower = user_answer.lower()
        chunk_lower = chunk_text.lower()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # KEYWORDS CRÃTICOS EXPANDIDOS (GENERALIZADO PARA CUALQUIER PDF)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Agrupados por categorÃ­a semÃ¡ntica - funciona para mÃºltiples dominios
        critical_keywords = {
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # ECONOMÃA / DINERO (expandido)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'dinero': ['dinero', 'francos', 'billetes', 'moneda', 'plata', 'efectivo', 
                       'suma', 'pago', 'precio', 'costo', 'valor', 'fortuna', 'riqueza',
                       'pobre', 'rico', 'deuda', 'prÃ©stamo', 'herencia', 'tesoro'],
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # ENVÃO / COMUNICACIÃ“N
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'envio': ['enviÃ³', 'enviaba', 'enviar', 'mandÃ³', 'mandaba', 'mandar', 
                      'recibÃ­a', 'recibiÃ³', 'recibir', 'entregÃ³', 'entregaba', 'entregar',
                      'llegÃ³', 'llegaba', 'llegar', 'trajo', 'traÃ­a', 'traer'],
            'correo': ['correo', 'carta', 'cartas', 'sobre', 'sobres', 'correspondencia',
                       'mensaje', 'mensajes', 'telegrama', 'paquete', 'envÃ­o'],
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # AYUDA / ASISTENCIA
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'ayuda': ['ayuda', 'ayudÃ³', 'ayudaba', 'ayudar', 'asistencia', 'apoyo',
                      'auxilio', 'socorro', 'colaboraciÃ³n', 'contribuciÃ³n', 'donaciÃ³n'],
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # CRIMEN / JUSTICIA
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'robo': ['robÃ³', 'robar', 'robo', 'hurto', 'ladrÃ³n', 'robado', 'robaron',
                     'sustrajo', 'sustraer', 'apropiÃ³', 'apropiar', 'estafÃ³', 'estafa'],
            'culpa': ['culpable', 'inocente', 'sospechoso', 'acusado', 'condenado',
                      'absuelto', 'criminal', 'delincuente', 'cÃ³mplice', 'vÃ­ctima'],
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # EXISTENCIA / OCURRENCIA (NUEVO - GENERAL)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'existencia': ['existiÃ³', 'existÃ­a', 'existe', 'existir', 'hubo', 'habÃ­a',
                           'ocurriÃ³', 'ocurrÃ­a', 'ocurrir', 'sucediÃ³', 'sucedÃ­a', 'suceder',
                           'pasÃ³', 'pasaba', 'pasar', 'aconteciÃ³', 'tuvo', 'tenÃ­a', 'tiene'],
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # VERDAD / CERTEZA (NUEVO - GENERAL)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'verdad': ['verdad', 'cierto', 'real', 'realidad', 'verdadero', 'autÃ©ntico',
                       'legÃ­timo', 'genuino', 'vÃ¡lido', 'confirmado', 'probado', 'demostrado'],
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # SALUD / ESTADO FÃSICO (NUEVO)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'salud': ['enfermo', 'enferma', 'enfermedad', 'salud', 'sano', 'sana',
                      'curÃ³', 'curaba', 'curar', 'muriÃ³', 'morÃ­a', 'morir', 'muerte',
                      'herido', 'herida', 'lesiÃ³n', 'recuperÃ³', 'recuperar', 'sobreviviÃ³'],
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # EMOCIONES / SENTIMIENTOS (NUEVO)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'emocion': ['feliz', 'triste', 'alegre', 'miedo', 'asustado', 'contento',
                        'enojado', 'furioso', 'preocupado', 'ansioso', 'nervioso', 'tranquilo',
                        'enamorado', 'amaba', 'odiaba', 'querÃ­a', 'deseaba', 'temÃ­a', 'esperaba'],
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # EVENTOS / SUCESOS (NUEVO)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'evento': ['guerra', 'batalla', 'conflicto', 'revoluciÃ³n', 'terremoto', 'accidente',
                       'incendio', 'inundaciÃ³n', 'catÃ¡strofe', 'desastre', 'celebraciÃ³n', 'fiesta',
                       'boda', 'funeral', 'nacimiento', 'reuniÃ³n', 'encuentro', 'viaje'],
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # TIEMPO / TEMPORALIDAD (NUEVO)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'tiempo': ['antes', 'despuÃ©s', 'durante', 'siempre', 'frecuentemente',
                       'diariamente', 'anualmente', 'mensualmente', 'primero', 'Ãºltimo',
                       'antiguo', 'moderno', 'reciente', 'pasado', 'futuro', 'presente'],
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # UBICACIÃ“N / LUGAR (NUEVO)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'ubicacion': ['aquÃ­', 'allÃ­', 'cerca', 'lejos', 'dentro', 'fuera', 'arriba', 'abajo',
                          'norte', 'sur', 'este', 'oeste', 'ciudad', 'pueblo', 'paÃ­s', 'regiÃ³n',
                          'casa', 'edificio', 'palacio', 'habitaciÃ³n', 'lugar', 'sitio'],
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # PERSONAS / RELACIONES (NUEVO)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'persona': ['padre', 'madre', 'hijo', 'hija', 'hermano', 'hermana', 'esposo', 'esposa',
                        'amigo', 'enemigo', 'rey', 'reina', 'conde', 'condesa', 'seÃ±or', 'seÃ±ora',
                        'jefe', 'empleado', 'sirviente', 'criado', 'niÃ±o', 'adulto', 'anciano'],
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # ACCIONES / VERBOS COMUNES (NUEVO)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'accion': ['hizo', 'hacÃ­a', 'hacer', 'dijo', 'decÃ­a', 'decir', 'vio', 'veÃ­a', 'ver',
                       'oyÃ³', 'oÃ­a', 'oÃ­r', 'sabÃ­a', 'saber', 'conocÃ­a', 'conocer', 'pensaba', 'pensar',
                       'quiso', 'querÃ­a', 'querer', 'pudo', 'podÃ­a', 'poder', 'debÃ­a', 'deber',
                       'logrÃ³', 'lograr', 'consiguiÃ³', 'conseguir', 'intentÃ³', 'intentar',
                       'decidiÃ³', 'decidir', 'descubriÃ³', 'descubrir', 'encontrÃ³', 'encontrar'],
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # CANTIDAD / NÃšMEROS (NUEVO)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'cantidad': ['todo', 'nada', 'mucho', 'poco', 'algunos', 'ninguno', 'varios',
                         'Ãºnico', 'solo', 'solamente', 'doble', 'triple', 'mitad', 'completo',
                         'mayorÃ­a', 'minorÃ­a', 'total', 'parcial', 'entero'],
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # CIENCIA / ACADÃ‰MICO (NUEVO)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            'ciencia': ['experimento', 'teorÃ­a', 'hipÃ³tesis', 'resultado', 'conclusiÃ³n',
                        'descubrimiento', 'invento', 'investigaciÃ³n', 'estudio', 'anÃ¡lisis',
                        'prueba', 'evidencia', 'demostraciÃ³n', 'fÃ³rmula', 'ley', 'principio'],
        }
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PATRONES DE NEGACIÃ“N EXPANDIDOS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        negation_patterns = [
            # Patrones directos (negaciÃ³n + keyword)
            r'\bno\s+{keyword}\b',
            r'\bnunca\s+{keyword}\b',
            r'\bjamÃ¡s\s+{keyword}\b',
            r'\bsin\s+{keyword}\b',
            r'\bningÃºn\s+{keyword}\b',
            r'\bninguna\s+{keyword}\b',
            r'\bnada\s+de\s+{keyword}\b',
            r'\bnadie\s+{keyword}\b',
            # Patrones con 1 palabra intermedia
            r'\bno\s+\w+\s+{keyword}\b',
            r'\bnunca\s+\w+\s+{keyword}\b',
            r'\bno\s+le\s+\w+\s+{keyword}\b',
            r'\bnunca\s+le\s+\w+\s+{keyword}\b',
            r'\bno\s+se\s+\w+\s+{keyword}\b',
            r'\bnunca\s+se\s+\w+\s+{keyword}\b',
            # Patrones con 2 palabras intermedias
            r'\bno\s+\w+\s+\w+\s+{keyword}\b',
            r'\bnunca\s+\w+\s+\w+\s+{keyword}\b',
            r'\bjamÃ¡s\s+\w+\s+\w+\s+{keyword}\b',
            # Patrones con 3 palabras intermedias
            r'\bno\s+\w+\s+\w+\s+\w+\s+{keyword}\b',
            r'\bnunca\s+\w+\s+\w+\s+\w+\s+{keyword}\b',
            # Patrones compuestos con "pero"
            r'\bpero\s+no\s+{keyword}\b',
            r'\bpero\s+nunca\s+{keyword}\b',
            r'\bpero\s+no\s+\w+\s+{keyword}\b',
            r'\bpero\s+nunca\s+\w+\s+{keyword}\b',
            r'\bpero\s+nunca\s+\w+\s+\w+\s+{keyword}\b',
            # Patrones con "tampoco" (NUEVO)
            r'\btampoco\s+{keyword}\b',
            r'\btampoco\s+\w+\s+{keyword}\b',
            # Patrones con "ni" (NUEVO)
            r'\bni\s+{keyword}\b',
            r'\bni\s+\w+\s+{keyword}\b',
            r'\bni\s+siquiera\s+{keyword}\b',
        ]
        
        contradictions_found = []
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ESTRATEGIA 1: ContradicciÃ³n con el CHUNK
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        for category, keywords in critical_keywords.items():
            for keyword in keywords:
                # Verificar si el keyword estÃ¡ en el chunk (es relevante)
                if keyword in chunk_lower:
                    # Buscar si el usuario NIEGA este keyword
                    for pattern_template in negation_patterns:
                        pattern = pattern_template.format(keyword=keyword)
                        if re.search(pattern, answer_lower):
                            contradictions_found.append({
                                'category': category,
                                'keyword': keyword,
                                'pattern': pattern,
                                'source': 'chunk'
                            })
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ESTRATEGIA 2: ContradicciÃ³n con la PREGUNTA (EXPANDIDA)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        question_lower = question.lower() if question else ""
        
        # Detectar tema de la pregunta - EXPANDIDO para mÃºltiples dominios
        question_topics = {
            # EconÃ³mico
            'economico': ['ayuda econÃ³mica', 'dinero', 'econÃ³mica', 'francos', 'billetes', 
                          'pago', 'suma', 'precio', 'costo', 'fortuna', 'herencia', 'deuda'],
            # EnvÃ­o/ComunicaciÃ³n
            'envio': ['recibÃ­a', 'enviaba', 'mandaba', 'por correo', 'carta', 'mensaje',
                      'llegaba', 'entregaba', 'correspondencia'],
            # Existencia/Ocurrencia
            'existencia': ['ocurriÃ³', 'sucediÃ³', 'pasÃ³', 'hubo', 'existiÃ³', 'habÃ­a',
                           'tuvo lugar', 'aconteciÃ³', 'se produjo'],
            # Salud
            'salud': ['enfermedad', 'enfermo', 'muriÃ³', 'curÃ³', 'salud', 'herido',
                      'recuperÃ³', 'sobreviviÃ³', 'falleciÃ³'],
            # Emociones
            'emocion': ['sentÃ­a', 'emociÃ³n', 'feliz', 'triste', 'miedo', 'amaba',
                        'odiaba', 'querÃ­a', 'temÃ­a'],
            # Eventos
            'evento': ['guerra', 'batalla', 'accidente', 'celebraciÃ³n', 'boda',
                       'viaje', 'reuniÃ³n', 'encuentro'],
            # Verdad
            'verdad': ['verdad', 'cierto', 'real', 'confirmÃ³', 'demostrÃ³', 'probÃ³'],
            # Acciones
            'accion': ['hizo', 'dijo', 'decidiÃ³', 'logrÃ³', 'consiguiÃ³', 'intentÃ³',
                       'descubriÃ³', 'encontrÃ³', 'vio', 'oyÃ³'],
        }
        
        for topic, topic_keywords in question_topics.items():
            # Si la pregunta trata sobre este tema
            if any(tk in question_lower for tk in topic_keywords):
                # Buscar keywords relacionados de critical_keywords
                related_keywords = critical_keywords.get(topic, [])
                # TambiÃ©n agregar keywords del tema 'dinero' si es econÃ³mico
                if topic == 'economico':
                    related_keywords = related_keywords + critical_keywords.get('dinero', [])
                # Agregar keywords de existencia para temas de eventos
                if topic in ['evento', 'existencia']:
                    related_keywords = related_keywords + critical_keywords.get('existencia', [])
                
                for keyword in related_keywords:
                    for pattern_template in negation_patterns:
                        pattern = pattern_template.format(keyword=keyword)
                        if re.search(pattern, answer_lower):
                            # Evitar duplicados
                            if not any(c['keyword'] == keyword and c['source'] == 'question' for c in contradictions_found):
                                contradictions_found.append({
                                    'category': topic,
                                    'keyword': keyword,
                                    'pattern': pattern,
                                    'source': 'question'
                                })
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ESTRATEGIA 3: DetecciÃ³n de contradicciÃ³n numÃ©rica (NUEVO)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Si el chunk menciona un nÃºmero y la respuesta menciona otro diferente
        chunk_numbers = set(re.findall(r'\b\d+\b', chunk_lower))
        answer_numbers = set(re.findall(r'\b\d+\b', answer_lower))
        
        # Si hay nÃºmeros en ambos y no coinciden (excluyendo nÃºmeros muy comunes como 1, 2)
        significant_chunk_nums = {n for n in chunk_numbers if int(n) > 10}
        significant_answer_nums = {n for n in answer_numbers if int(n) > 10}
        
        if significant_chunk_nums and significant_answer_nums:
            mismatched = significant_answer_nums - significant_chunk_nums
            if mismatched and len(mismatched) > 0:
                # Hay nÃºmeros en la respuesta que no estÃ¡n en el chunk
                contradictions_found.append({
                    'category': 'numerico',
                    'keyword': f"nÃºmeros: {list(mismatched)[:2]}",
                    'pattern': 'numeric_mismatch',
                    'source': 'numeric'
                })
        
        if contradictions_found:
            # Cuantas mÃ¡s contradicciones, mayor penalizaciÃ³n
            num_contradictions = len(contradictions_found)
            
            # Verificar si hay contradicciones con la PREGUNTA (mÃ¡s graves)
            question_contradictions = [c for c in contradictions_found if c.get('source') == 'question']
            has_question_contradiction = len(question_contradictions) > 0
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # PENALIZACIÃ“N MÃS SEVERA:
            # - ContradicciÃ³n con la pregunta = muy grave (el usuario niega
            #   exactamente lo que la pregunta pregunta)
            # - MÃºltiples contradicciones = grave
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            
            if has_question_contradiction:
                # Si niega algo que la pregunta pregunta directamente
                # Ejemplo: pregunta sobre "ayuda econÃ³mica" y responde "nunca le mandÃ³ dinero"
                penalty = 0.20  # Reducir score al 20% (forzar rechazo)
                severity = "MUY GRAVE (contradice la pregunta)"
            elif num_contradictions >= 3:
                penalty = 0.25  # Reducir score al 25%
                severity = "GRAVE"
            elif num_contradictions >= 2:
                penalty = 0.30  # Reducir score al 30%
                severity = "MODERADA"
            else:
                penalty = 0.40  # Reducir score al 40%
                severity = "LEVE"
            
            keywords_negated = [c['keyword'] for c in contradictions_found[:3]]
            reason = f"ContradicciÃ³n {severity}: negaciÃ³n de '{', '.join(keywords_negated)}'"
            
            print(f"   âš ï¸ CONTRADICCIÃ“N DETECTADA: {reason}")
            print(f"   ğŸ“‰ PenalizaciÃ³n: score Ã— {penalty}")
            
            return True, penalty, reason
        
        return False, 1.0, ""
    
    def apply_pedagogical_boost(self, score_raw: float, cosine: float, 
                                user_answer: str, ref_text: str, question: str = "") -> float:
        """
        Booster pedagÃ³gico para respuestas de comprensiÃ³n lectora.
        
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        BASADO EN INVESTIGACIÃ“N:
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        1. Sentence-BERT (Reimers & Gurevych, 2019):
           - Cosine similarity en embeddings tiene rango efectivo [0.3-0.8]
           - Por debajo de 0.3: sin relaciÃ³n semÃ¡ntica
           - Por encima de 0.6: alta similitud
           
        2. Short Answer Grading (Lloyd et al., 2022):
           - Las respuestas parafraseadas son tan vÃ¡lidas como las literales
           - El contenido semÃ¡ntico importa mÃ¡s que las palabras exactas
           
        3. Reading Comprehension Strategies (EEF, 2025):
           - Preguntas inferenciales requieren conectar ideas
           - La respuesta correcta puede NO contener palabras del texto
           
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ESTRATEGIA DE BOOST:
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        A) LITERAL (recuerdo directo):
           - Threshold: cosine >= 0.40
           - Boost: x1.3 si respuesta concisa
           
        B) INFERENCIAL (razonamiento):
           - Threshold: cosine >= 0.35 (mÃ¡s flexible!)
           - Boost: x1.4 (reconoce esfuerzo cognitivo mayor)
           - El usuario puede usar palabras propias
        
        Args:
            score_raw: Score antes del boost [0,1]
            cosine: Similitud de embeddings normalizada [0,1]
            user_answer: Texto de la respuesta del usuario
            ref_text: Texto del chunk de referencia
            question: Texto de la pregunta (para detectar tipo)
            
        Returns:
            float: Score despuÃ©s del boost (mÃ¡x 0.99)
        """
        is_inferential = question and self.is_inferential_question(question)
        
        # Umbrales diferenciados segÃºn tipo de pregunta
        if is_inferential:
            # Preguntas inferenciales: mÃ¡s tolerantes
            # El usuario usa sus propias palabras para explicar
            BASE_THRESHOLD = 0.30      # MÃ¡s bajo: permite parafraseo
            BOOST_THRESHOLD = 0.35     # Umbral para boost
            BOOST_FACTOR = 1.45        # Boost mÃ¡s alto: reconoce razonamiento
            print(f"   ğŸ§  Pregunta INFERENCIAL detectada - umbral flexible")
        else:
            # Preguntas literales: estÃ¡ndar
            BASE_THRESHOLD = 0.40
            BOOST_THRESHOLD = 0.45
            BOOST_FACTOR = 1.30
        
        # Si estÃ¡ por debajo del umbral base, no hay boost
        if cosine < BASE_THRESHOLD:
            return score_raw
        
        # Calcular ratio de longitud (palabras)
        len_user = max(len(user_answer.split()), 1)
        len_ref = max(len(ref_text.split()), 1)
        len_ratio = len_user / len_ref
        
        boosted = score_raw
        
        # Boost 1: Respuestas concisas pero correctas (sÃ­ntesis)
        if len_ratio < 0.5 and cosine >= BOOST_THRESHOLD:
            # El usuario sintetizÃ³ bien la informaciÃ³n
            factor = 1.5 if len_ratio < 0.3 else 1.35
            boosted = score_raw * factor
            print(f"   ğŸ“ Boost sÃ­ntesis aplicado: x{factor:.2f}")
        
        # Boost 2: Preguntas inferenciales con respuesta razonada
        elif is_inferential and cosine >= BOOST_THRESHOLD:
            # El usuario demostrÃ³ comprensiÃ³n profunda
            boosted = score_raw * BOOST_FACTOR
            print(f"   ğŸ¯ Boost inferencial aplicado: x{BOOST_FACTOR:.2f}")
        
        # Limitar a 99% mÃ¡ximo (nunca dar 100% automÃ¡ticamente)
        return min(boosted, 0.99)
    
    def normalize_embedding(self, embedding: np.ndarray) -> np.ndarray:
        norm = np.linalg.norm(embedding)
        if norm < 1e-10:  # Threshold para evitar division por cero o numeros muy pequeÃ±os
            return embedding
        return embedding / norm
    
    def extract_keywords(self, text: str):
        # Normalizar texto antes de extraer keywords (quitar espacios OCR)
        # Ejemplo: "H enriet te" â†’ "Henriette"
        text = re.sub(r'\b(\w{1,2})\s+(\w{1,2})\b', r'\1\2', text)
        for _ in range(3):
            text = re.sub(r'\b(\w{1,2})\s+(\w{1,2})\b', r'\1\2', text)
        text = re.sub(r'\b(\w{2,4})\s+(\w{3,6})\b', r'\1\2', text)
        
        text = text.lower()
        words = re.findall(r'\b\w{3,}\b', text)
        keywords = [w for w in words if w not in self.stopwords]
        return keywords
    
    def expand_keywords(self, keywords):
        expanded = set(keywords)
        for word in keywords:
            expanded.add(word)
            if len(word) >= 6:
                expanded.add(word[:6])
            elif len(word) >= 5:
                expanded.add(word[:5])
            if word[0].isupper():
                expanded.add(word.lower())
        return expanded
    
    def bm25_score(self, query_keywords, chunk_text: str, corpus):
        tokenized_corpus = [self.extract_keywords(text) for text in corpus]
        
        # ProtecciÃ³n: si el corpus estÃ¡ vacÃ­o o todos los documentos vacÃ­os
        if not tokenized_corpus or all(len(doc) == 0 for doc in tokenized_corpus):
            return 0.0
        
        bm25 = BM25Okapi(tokenized_corpus)
        expanded_query = list(self.expand_keywords(query_keywords))
        
        # ProtecciÃ³n: si la query estÃ¡ vacÃ­a
        if not expanded_query:
            return 0.0
        
        scores = bm25.get_scores(expanded_query)
        chunk_keywords = self.extract_keywords(chunk_text)
        try:
            chunk_index = tokenized_corpus.index(chunk_keywords)
            return scores[chunk_index]
        except ValueError:
            return np.mean(scores) if len(scores) > 0 else 0.0
    
    def cosine_similarity(self, emb1: np.ndarray, emb2: np.ndarray) -> float:
        emb1_norm = self.normalize_embedding(emb1)
        emb2_norm = self.normalize_embedding(emb2)
        similarity = np.dot(emb1_norm, emb2_norm)
        return max(0.0, min(1.0, similarity))
    
    def calculate_coverage(self, answer_keywords, chunk_keywords):
        answer_expanded = self.expand_keywords(answer_keywords)
        chunk_expanded = self.expand_keywords(chunk_keywords)
        intersection = answer_expanded & chunk_expanded
        if len(answer_expanded) == 0:
            return 0.0
        coverage = len(intersection) / len(answer_expanded)
        return coverage
    
    def hybrid_score(self, question: str, answer: str, chunk, all_chunks):
        question_keywords = self.extract_keywords(question)
        answer_keywords = self.extract_keywords(answer)
        combined_keywords = list(set(question_keywords + answer_keywords))
        
        answer_embedding = self.normalize_embedding(
            self.model.encode(answer, convert_to_tensor=False)
        )
        chunk_embedding = self.normalize_embedding(
            np.array(chunk['embedding'])
        )
        
        corpus = [c['text_full'] for c in all_chunks]
        bm25_score_raw = self.bm25_score(combined_keywords, chunk['text_full'], corpus)
        bm25_normalized = min(1.0, bm25_score_raw / 10.0)
        
        cosine_score_raw = self.cosine_similarity(answer_embedding, chunk_embedding)
        # NUEVO: Normalizar cosine al rango 0-1 basado en valores empÃ­ricos
        cosine_normalized = self.normalize_cosine(cosine_score_raw)
        
        chunk_keywords = self.extract_keywords(chunk['text_full'])
        coverage_score = self.calculate_coverage(answer_keywords, chunk_keywords)
        
        # Score base: combinar mÃ©tricas normalizadas con pesos calibrados
        # 80% semÃ¡ntica + 15% cobertura + 5% lÃ©xico (reducido por OCR)
        score_base = (
            self.weights['bm25'] * bm25_normalized +
            self.weights['cosine'] * cosine_normalized +
            self.weights['coverage'] * coverage_score
        )
        
        # Aplicar bonus por longitud razonable (+5% mÃ¡ximo)
        bonus = self.length_bonus(answer)
        score_raw = max(0.0, min(1.0, score_base + bonus))  # Clamp a [0,1]
        
        # NUEVO: Aplicar boost pedagÃ³gico para respuestas concisas pero correctas
        # + boost inferencial para preguntas de razonamiento
        score_raw = self.apply_pedagogical_boost(
            score_raw=score_raw,
            cosine=cosine_normalized,
            user_answer=answer,
            ref_text=chunk['text_full'],
            question=question  # Para detectar preguntas inferenciales
        )
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # NUEVO: Re-ranking basado en tipo de pregunta (Rationale-Aware)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Si la pregunta es de razonamiento, dar boost a chunks con mÃ¡s
        # diÃ¡logo y verbos de pensamiento/opiniÃ³n
        question_type = self.classify_question_type(question)
        reasoning_score = self.compute_reasoning_score(chunk['text_full'])
        reasoning_boost_applied = 0.0
        
        if question_type == 'reasoning' and reasoning_score > 0.1:
            # Boost suave: mÃ¡ximo +20% al score
            # No rompe el score semÃ¡ntico, solo inclina la balanza
            reasoning_boost_applied = 0.20 * reasoning_score
            score_raw = score_raw * (1 + reasoning_boost_applied)
            score_raw = min(score_raw, 0.99)  # Nunca superar 99%
            print(f"   ğŸ§  Boost razonamiento: +{reasoning_boost_applied*100:.1f}% (reasoning_score={reasoning_score:.2f})")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # NUEVO: DetecciÃ³n de contradicciÃ³n (NLI simplificado)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Si el usuario NIEGA conceptos clave del chunk, penalizar fuertemente
        # Ejemplo: chunk dice "recibÃ­a dinero" â†’ usuario dice "nunca le mandÃ³ dinero"
        is_contradiction, penalty_factor, contradiction_reason = self.detect_contradiction(
            user_answer=answer,
            chunk_text=chunk['text_full'],
            question=question
        )
        
        if is_contradiction:
            score_raw = score_raw * penalty_factor
            print(f"   ğŸ“‰ Score despuÃ©s de penalizaciÃ³n: {score_raw:.4f}")
        
        # Convertir a porcentaje 0-100% con min-max scaling
        score_pct = self.to_percentage(score_raw)
        
        details = {
            'bm25': round(bm25_normalized, 4),
            'cosine': round(cosine_score_raw, 4),  # Raw para logs
            'cosine_normalized': round(cosine_normalized, 4),  # Normalizado
            'coverage': round(coverage_score, 4),
            'score_base': round(score_base, 4),
            'length_bonus': round(bonus, 4),
            'score_raw': round(score_raw, 4),  # Score bruto [0,1]
            'score_pct': score_pct,  # Porcentaje [0-100]
            'final': round(score_raw, 4),  # Mantener compatibilidad
            'weights': self.weights,
            'keywords_found': list(
                self.expand_keywords(answer_keywords) & 
                self.expand_keywords(chunk_keywords)
            )[:5],
            # NUEVO: Info de contradicciÃ³n para debugging
            'contradiction_detected': is_contradiction,
            'contradiction_reason': contradiction_reason if is_contradiction else None,
            'contradiction_penalty': penalty_factor if is_contradiction else 1.0,
            # NUEVO: Info de re-ranking por tipo de pregunta
            'question_type': question_type,
            'reasoning_score': round(reasoning_score, 4),
            'reasoning_boost': round(reasoning_boost_applied, 4)
        }
        
        return score_raw, details
    
    def detect_ambiguity(self, ranked_chunks):
        if len(ranked_chunks) < 2:
            return {'is_ambiguous': False, 'reason': 'Menos de 2 chunks'}
        
        top1_score = ranked_chunks[0][1]
        top2_score = ranked_chunks[1][1]
        score_diff = top1_score - top2_score
        is_ambiguous = score_diff < 0.08
        
        return {
            'is_ambiguous': is_ambiguous,
            'score_diff': round(score_diff, 4),
            'top1_score': round(top1_score, 4),
            'top2_score': round(top2_score, 4),
            'threshold': 0.08
        }
    
    def validate_answer(self, question: str, user_answer: str, chunks):
        if not chunks or len(chunks) == 0:
            return {
                'is_valid': False,
                'confidence': 0.0,
                'feedback': 'No hay chunks disponibles para validacion',
                'category': 'error'
            }
        
        if len(user_answer.strip()) < 10:
            return {
                'is_valid': False,
                'confidence': 0.0,
                'feedback': 'La respuesta es demasiado corta (minimo 10 caracteres)',
                'category': 'error'
            }
        
        scored_chunks = []
        for chunk in chunks:
            score, details = self.hybrid_score(question, user_answer, chunk, chunks)
            scored_chunks.append((chunk, score, details))
        
        ranked_chunks = sorted(scored_chunks, key=lambda x: x[1], reverse=True)
        top_k = ranked_chunks[:3]
        
        ambiguity = self.detect_ambiguity([(c, s) for c, s, _ in ranked_chunks])
        
        best_chunk, best_score_raw, best_details = top_k[0]
        best_score_pct = best_details['score_pct']  # Usar porcentaje para UI
        
        # ClasificaciÃ³n basada en score_raw (0-1)
        if best_score_raw >= self.thresholds['excelente']:
            category = 'excelente'
            is_valid = True
            feedback = 'Excelente! Tu respuesta captura perfectamente el contenido.'
        elif best_score_raw >= self.thresholds['bueno']:
            category = 'bueno'
            is_valid = True
            feedback = 'Muy bien. Tu respuesta es correcta y bien fundamentada.'
        elif best_score_raw >= self.thresholds['aceptable']:
            category = 'aceptable'
            is_valid = True
            feedback = 'Aceptable. Tu respuesta esta en la direccion correcta.'
        else:
            category = 'necesita_mejorar'
            is_valid = False
            feedback = 'Tu respuesta necesita mÃ¡s trabajo. Revisa el material.'
        
        result = {
            'is_valid': is_valid,
            'confidence': best_score_pct,  # Porcentaje 0-100
            'score_raw': round(best_score_raw, 4),  # Score bruto [0,1]
            'feedback': feedback,
            'category': category,
            'best_chunk': {
                'text': best_chunk['text_full'][:200] + '...' if len(best_chunk['text_full']) > 200 else best_chunk['text_full'],
                'page': best_chunk.get('page_number', 'N/A'),
                'chunk_id': best_chunk.get('chunk_id', 'N/A')
            },
            'top_3_scores': [
                {
                    'score': d['score_pct'],  # Porcentaje
                    'score_raw': d['score_raw'],  # Bruto
                    'chunk_id': c.get('chunk_id', 'N/A'),
                    'details': d
                }
                for c, s, d in top_k
            ],
            'ambiguity': ambiguity,
            'thresholds': {k: v * 100 for k, v in self.thresholds.items()},
            'scoring_method': 'HybridValidator (BM25 + Cosine + Coverage)',
            'weights_used': self.weights
        }
        
        return result
