"""
ANALIZADOR GRAMATICAL ESPAÃ‘OL - RECUIVA
========================================

MÃ³dulo especializado en gramÃ¡tica espaÃ±ola para distinguir:
- Nombres propios (personas, lugares) vs objetos comunes
- Sujeto vs predicado vs complementos
- Sustantivos vs verbos vs adjetivos
- GÃ©nero y nÃºmero gramatical
- NUEVO: ClasificaciÃ³n UNIVERSAL de entidades (persona, concepto, objeto, proceso)

PROBLEMA RESUELTO:
âŒ ANTES: "Estaba y Ahol", "Henriet y Ancuet" (nombres mal formados)
âœ… AHORA: Valida contexto gramatical antes de extraer

Autor: Abel JesÃºs Moya Acosta
Fecha: 10 de noviembre de 2025
Proyecto: Recuiva - Active Recall con IA
"""

import re
from typing import List, Dict, Tuple, Set, Optional
from dataclasses import dataclass
from enum import Enum

# Importar tipos universales
from universal_entity_types import (
    EntityType,
    UNIVERSAL_INDICATORS,
    CONTEXT_VERBS,
    is_function_word
)


class WordType(Enum):
    """Tipos gramaticales en espaÃ±ol"""
    NOMBRE_PROPIO = "nombre_propio"      # MarÃ­a, ParÃ­s, EspaÃ±a
    SUSTANTIVO_COMUN = "sustantivo"      # casa, collar, ventana
    VERBO = "verbo"                      # correr, hablar, ser
    ADJETIVO = "adjetivo"                # grande, azul, hermoso
    ARTICULO = "articulo"                # el, la, un, una
    PREPOSICION = "preposicion"          # de, en, con, por
    PRONOMBRE = "pronombre"              # Ã©l, ella, usted


@dataclass
class GrammaticalEntity:
    """Entidad gramatical extraÃ­da del texto"""
    text: str                    # Texto original
    word_type: WordType          # Tipo gramatical
    confidence: float            # Confianza (0-1)
    context: str                 # Contexto donde aparece
    is_person: bool              # Es nombre de persona
    gender: Optional[str] = None # masculino/femenino/neutro
    number: Optional[str] = None # singular/plural


class SpanishGrammarAnalyzer:
    """
    Analizador especializado en gramÃ¡tica espaÃ±ola
    
    REGLAS IMPLEMENTADAS:
    1. Nombres propios: MayÃºscula + contexto verbal de persona
    2. Sujeto: Quien realiza la acciÃ³n (antes del verbo)
    3. Predicado: Verbo + complementos
    4. ValidaciÃ³n de gÃ©nero/nÃºmero
    """
    
    # ===== DICCIONARIOS GRAMATICALES =====
    
    # ArtÃ­culos definidos e indefinidos
    ARTICULOS = {
        'el', 'la', 'los', 'las',       # Definidos
        'un', 'una', 'unos', 'unas'     # Indefinidos
    }
    
    # Preposiciones comunes
    PREPOSICIONES = {
        'a', 'ante', 'bajo', 'con', 'contra', 'de', 'desde', 'durante',
        'en', 'entre', 'hacia', 'hasta', 'mediante', 'para', 'por',
        'segÃºn', 'sin', 'sobre', 'tras'
    }
    
    # Pronombres personales
    PRONOMBRES = {
        'yo', 'tÃº', 'Ã©l', 'ella', 'usted', 'nosotros', 'nosotras',
        'vosotros', 'vosotras', 'ellos', 'ellas', 'ustedes',
        'me', 'te', 'se', 'lo', 'la', 'le', 'nos', 'os', 'les'
    }
    
    # Verbos auxiliares y copulativos
    VERBOS_AUXILIARES = {
        'ser', 'estar', 'haber', 'tener', 'poder', 'deber',
        'es', 'estÃ¡', 'estaba', 'era', 'fue', 'habÃ­a', 'hubo',
        'tiene', 'tenÃ­a', 'tuvo', 'puede', 'podÃ­a', 'pudo'
    }
    
    # Verbos de acciÃ³n comunes (infinitivos y conjugaciones frecuentes)
    VERBOS_ACCION = {
        'hacer', 'hizo', 'hice', 'decir', 'dijo', 'dije',
        'ver', 'vio', 'vi', 'dar', 'dio', 'di',
        'poner', 'puso', 'puse', 'tomar', 'tomÃ³', 'tomÃ©',
        'llevar', 'llevÃ³', 'llevÃ©', 'dejar', 'dejÃ³', 'dejÃ©',
        'llamar', 'llamÃ³', 'llamÃ©', 'encontrar', 'encontrÃ³', 'encontrÃ©',
        'pensar', 'pensÃ³', 'pensÃ©', 'creer', 'creyÃ³', 'creÃ­',
        'mirar', 'mirÃ³', 'mirÃ©', 'parecer', 'pareciÃ³', 'parecÃ­',
        'quedar', 'quedÃ³', 'quedÃ©', 'seguir', 'siguiÃ³', 'seguÃ­',
        'venir', 'vino', 'vine', 'salir', 'saliÃ³', 'salÃ­',
        'entrar', 'entrÃ³', 'entrÃ©', 'preguntar', 'preguntÃ³', 'preguntÃ©',
        'responder', 'respondiÃ³', 'respondÃ­', 'abrir', 'abriÃ³', 'abrÃ­',
        'cerrar', 'cerrÃ³', 'cerrÃ©', 'ofrecer', 'ofreciÃ³', 'ofrecÃ­',
        'comprender', 'comprendiÃ³', 'comprendÃ­', 'conocer', 'conociÃ³', 'conocÃ­'
    }
    
    # Sustantivos comunes que NO son nombres propios (aunque empiecen con mayÃºscula en tÃ­tulos)
    SUSTANTIVOS_COMUNES = {
        'libro', 'casa', 'ventana', 'puerta', 'collar', 'anillo', 'joya',
        'habitaciÃ³n', 'patio', 'gabinete', 'edificio', 'calle', 'camino',
        'noche', 'dÃ­a', 'maÃ±ana', 'tarde', 'aÃ±o', 'mes', 'semana',
        'hombre', 'mujer', 'niÃ±o', 'niÃ±a', 'persona', 'gente',
        'seÃ±or', 'seÃ±ora', 'conde', 'condesa', 'rey', 'reina', 'cardenal',
        'esposa', 'marido', 'hijo', 'hija', 'sobrino', 'sobrina', 'tÃ­o', 'tÃ­a',
        'mano', 'ojo', 'cara', 'voz', 'palabra', 'gesto',
        'diamante', 'oro', 'plata', 'piedra', 'montura',
        'objeto', 'cosa', 'lugar', 'sitio', 'parte'
    }
    
    # TÃ­tulos y tratamientos que indican persona
    TITULOS_PERSONA = {
        'seÃ±or', 'seÃ±ora', 'don', 'doÃ±a', 'conde', 'condesa',
        'duque', 'duquesa', 'rey', 'reina', 'prÃ­ncipe', 'princesa',
        'cardenal', 'obispo', 'papa', 'doctor', 'doctora',
        'profesor', 'profesora', 'ingeniero', 'ingeniera'
    }
    
    # Conectores de nombres compuestos
    CONECTORES_NOMBRES = {'de', 'del', 'la', 'y'}
    
    def __init__(self):
        """Inicializa el analizador gramatical"""
        self.stats = {
            'entities_extracted': 0,
            'proper_nouns_found': 0,
            'common_nouns_found': 0
        }
    
    def extract_proper_nouns(
        self,
        text: str,
        min_confidence: float = 0.6
    ) -> List[GrammaticalEntity]:
        """
        Extrae nombres propios con validaciÃ³n gramatical
        
        MEJORAS vs ContentAnalyzer:
        - âœ… Valida contexto gramatical (no solo mayÃºsculas)
        - âœ… Distingue "Toca" (objeto) de "MarÃ­a" (persona)
        - âœ… Detecta tÃ­tulos ("seÃ±or Dreux", "condesa de X")
        - âœ… Maneja nombres compuestos ("MarÃ­a Antonieta", "Luis de Francia")
        
        Args:
            text: Texto a analizar
            min_confidence: Confianza mÃ­nima (0-1)
            
        Returns:
            Lista de entidades gramaticales validadas
        """
        entities = []
        
        # PASO 1: Buscar nombres con tÃ­tulos (alta confianza)
        # PatrÃ³n: "seÃ±or/condesa/etc + Nombre(s)"
        title_pattern = r'\b(' + '|'.join(self.TITULOS_PERSONA) + r')\s+([A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+(?:\s+(?:de|del|la|y)\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+)*(?:\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+){0,2})\b'
        
        for match in re.finditer(title_pattern, text, re.IGNORECASE):
            title = match.group(1).lower()
            name = match.group(2)
            
            # Determinar gÃ©nero por tÃ­tulo
            gender = self._detect_gender_from_title(title)
            
            entities.append(GrammaticalEntity(
                text=name,
                word_type=WordType.NOMBRE_PROPIO,
                confidence=0.95,  # Alta confianza (tiene tÃ­tulo)
                context=match.group(0),
                is_person=True,
                gender=gender,
                number='singular'
            ))
        
        # PASO 2: Buscar nombres propios sin tÃ­tulo (validaciÃ³n contextual)
        # PatrÃ³n: 1-4 palabras capitalizadas, permitiendo conectores
        name_pattern = r'\b([A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+(?:\s+(?:de|del|la|y)\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+)*(?:\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+){0,2})\b'
        
        for match in re.finditer(name_pattern, text):
            name_candidate = match.group(1)
            
            # VALIDACIÃ“N 1: Omitir si es sustantivo comÃºn conocido
            first_word = name_candidate.split()[0].lower()
            if first_word in self.SUSTANTIVOS_COMUNES:
                continue
            
            # VALIDACIÃ“N 2: Omitir si estÃ¡ en lista negra
            if self._is_blacklisted_term(name_candidate):
                continue
            
            # VALIDACIÃ“N 3: Analizar contexto gramatical
            start_pos = max(0, match.start() - 50)
            end_pos = min(len(text), match.end() + 50)
            context = text[start_pos:end_pos]
            
            confidence = self._calculate_name_confidence(name_candidate, context)
            
            if confidence >= min_confidence:
                # Verificar si ya fue extraÃ­do con tÃ­tulo
                if not any(e.text == name_candidate for e in entities):
                    entities.append(GrammaticalEntity(
                        text=name_candidate,
                        word_type=WordType.NOMBRE_PROPIO,
                        confidence=confidence,
                        context=context,
                        is_person=self._is_person_name(name_candidate, context),
                        gender=self._detect_gender_from_context(context),
                        number='singular'
                    ))
        
        # PASO 3: Deduplicar y ordenar por confianza
        seen = set()
        unique_entities = []
        
        for entity in sorted(entities, key=lambda e: e.confidence, reverse=True):
            # Normalizar para comparaciÃ³n
            normalized = entity.text.lower().strip()
            
            if normalized not in seen:
                seen.add(normalized)
                unique_entities.append(entity)
                self.stats['entities_extracted'] += 1
                if entity.is_person:
                    self.stats['proper_nouns_found'] += 1
        
        return unique_entities
    
    def _detect_gender_from_title(self, title: str) -> str:
        """Detecta gÃ©nero gramatical por tÃ­tulo"""
        feminine_titles = {'seÃ±ora', 'doÃ±a', 'condesa', 'duquesa', 'reina', 'princesa', 'doctora', 'profesora', 'ingeniera'}
        
        if title.lower() in feminine_titles:
            return 'femenino'
        else:
            return 'masculino'
    
    def _is_blacklisted_term(self, term: str) -> bool:
        """
        Verifica si el tÃ©rmino es un falso positivo comÃºn
        
        LISTA NEGRA:
        - Inicio de oraciones genÃ©ricas ("Dos o tres", "Era en")
        - Objetos comunes ("Toca", "Collar", "Ventana")
        - Conectores mal capitalizados
        """
        blacklist = {
            # NÃºmeros/cuantificadores
            'Dos', 'Tres', 'Cuatro', 'Cinco', 'Muchos', 'Varios', 'Algunos',
            
            # Objetos del "Collar de la Reina"
            'Toca', 'Collar', 'Ventana', 'Puerta', 'HabitaciÃ³n', 'Patio',
            'Gabinete', 'Edificio', 'Diamante', 'Montura',
            
            # Temporales
            'Era', 'Fue', 'HabÃ­a', 'Noche', 'DÃ­a', 'MaÃ±ana', 'Tarde',
            
            # Inicio de oraciÃ³n genÃ©rico
            'De', 'En', 'Con', 'Por', 'Para', 'Sobre', 'Entre'
        }
        
        first_word = term.split()[0]
        return first_word in blacklist
    
    def _calculate_name_confidence(self, name: str, context: str) -> float:
        """
        Calcula confianza de que sea nombre propio
        
        FACTORES:
        1. Longitud (nombres muy cortos = baja confianza)
        2. Presencia de verbos de acciÃ³n cerca (sujeto probable)
        3. Preposiciones "de"/"del" antes (tÃ­tulos nobiliarios)
        4. ArtÃ­culos antes (probablemente objeto comÃºn)
        """
        confidence = 0.5  # Base
        
        # FACTOR 1: Longitud y estructura
        words = name.split()
        if len(words) >= 2:
            confidence += 0.2  # Nombres compuestos son mÃ¡s probables
        elif len(words) == 1 and len(name) <= 4:
            confidence -= 0.2  # Nombres muy cortos son dudosos
        
        # FACTOR 2: Contexto verbal (es sujeto de una acciÃ³n)
        context_lower = context.lower()
        for verb in self.VERBOS_ACCION:
            if verb in context_lower:
                # Buscar si el nombre estÃ¡ antes del verbo (patrÃ³n sujeto-verbo)
                name_pos = context_lower.find(name.lower())
                verb_pos = context_lower.find(verb)
                
                if name_pos < verb_pos and (verb_pos - name_pos) < 30:
                    confidence += 0.15
                    break
        
        # FACTOR 3: TÃ­tulos nobiliarios ("conde de X", "duque de Y")
        if re.search(r'\b(?:de|del)\s+' + re.escape(name), context, re.IGNORECASE):
            # Verificar si hay tÃ­tulo antes
            if any(title in context_lower for title in self.TITULOS_PERSONA):
                confidence += 0.25
        
        # FACTOR 4: ArtÃ­culos antes (indica objeto comÃºn)
        for article in self.ARTICULOS:
            if re.search(r'\b' + article + r'\s+' + re.escape(name), context, re.IGNORECASE):
                confidence -= 0.3  # "el Toca", "la Ventana" = no es nombre
                break
        
        # FACTOR 5: Conectores de nombres compuestos
        if any(conn in name.lower() for conn in ['de', 'del', 'la', 'y']):
            confidence += 0.15  # "MarÃ­a de Francia", "Juan y Pedro"
        
        return min(1.0, max(0.0, confidence))
    
    def _is_person_name(self, name: str, context: str) -> bool:
        """
        Determina si el nombre es de una persona (vs lugar/cosa)
        
        HEURÃSTICAS:
        - Verbos de diÃ¡logo cerca ("dijo X", "preguntÃ³ Y")
        - Pronombres personales ("Ã©l", "ella", "usted")
        - Posesivos de persona ("su", "sus" + nombre)
        """
        context_lower = context.lower()
        name_lower = name.lower()
        
        # Verbos de diÃ¡logo (fuerte indicador de persona)
        dialogue_verbs = {
            'dijo', 'preguntÃ³', 'respondiÃ³', 'exclamÃ³', 'gritÃ³', 'susurrÃ³',
            'contestÃ³', 'murmurÃ³', 'replicÃ³', 'aÃ±adiÃ³', 'continuÃ³'
        }
        
        for verb in dialogue_verbs:
            if re.search(r'\b' + re.escape(name_lower) + r'\s+' + verb, context_lower):
                return True
            if re.search(verb + r'\s+' + re.escape(name_lower), context_lower):
                return True
        
        # Pronombres personales cerca
        if re.search(r'\b(?:Ã©l|ella|usted|seÃ±or|seÃ±ora)\b.*' + re.escape(name_lower), context_lower):
            return True
        
        # Verbos de acciÃ³n con el nombre como sujeto
        for verb in ['entrÃ³', 'saliÃ³', 'caminÃ³', 'mirÃ³', 'pensÃ³', 'sintiÃ³']:
            if re.search(r'\b' + re.escape(name_lower) + r'\s+' + verb, context_lower):
                return True
        
        return False
    
    def _detect_gender_from_context(self, context: str) -> Optional[str]:
        """Detecta gÃ©nero por contexto (pronombres, artÃ­culos)"""
        context_lower = context.lower()
        
        # Pronombres/artÃ­culos masculinos
        if re.search(r'\b(?:Ã©l|seÃ±or|don|el)\b', context_lower):
            return 'masculino'
        
        # Pronombres/artÃ­culos femeninos
        if re.search(r'\b(?:ella|seÃ±ora|doÃ±a|la)\b', context_lower):
            return 'femenino'
        
        return None
    
    def identify_subject_predicate(self, sentence: str) -> Dict[str, str]:
        """
        Identifica sujeto y predicado en una oraciÃ³n
        
        REGLAS:
        - Sujeto: Quien realiza la acciÃ³n (antes del verbo principal)
        - Predicado: Verbo + complementos
        
        Returns:
            {'subject': str, 'predicate': str, 'verb': str}
        """
        # Buscar verbo principal
        words = sentence.split()
        verb_pos = -1
        main_verb = ""
        
        for i, word in enumerate(words):
            word_lower = word.lower().strip('.,;:!?')
            if word_lower in self.VERBOS_ACCION or word_lower in self.VERBOS_AUXILIARES:
                verb_pos = i
                main_verb = word_lower
                break
        
        if verb_pos == -1:
            return {'subject': '', 'predicate': sentence, 'verb': ''}
        
        # Sujeto: palabras antes del verbo (excluyendo artÃ­culos/preposiciones)
        subject_words = []
        for i in range(verb_pos):
            word = words[i].strip('.,;:!?')
            word_lower = word.lower()
            
            # Omitir artÃ­culos y preposiciones iniciales
            if word_lower not in self.ARTICULOS and word_lower not in self.PREPOSICIONES:
                subject_words.append(word)
        
        subject = ' '.join(subject_words) if subject_words else '(sujeto tÃ¡cito)'
        predicate = ' '.join(words[verb_pos:])
        
        return {
            'subject': subject,
            'predicate': predicate,
            'verb': main_verb
        }
    
    def get_stats(self) -> Dict:
        """Retorna estadÃ­sticas del analizador"""
        return self.stats


# ===== FUNCIÃ“N DE INTEGRACIÃ“N =====

def extract_validated_names(text: str) -> List[str]:
    """
    Wrapper para integraciÃ³n rÃ¡pida con content_analyzer.py
    
    Args:
        text: Chunk de texto a analizar
        
    Returns:
        Lista de nombres propios validados (solo texto)
    """
    analyzer = SpanishGrammarAnalyzer()
    entities = analyzer.extract_proper_nouns(text, min_confidence=0.6)
    
    # Filtrar solo personas y ordenar por confianza
    person_names = [
        e.text for e in entities
        if e.is_person and e.confidence >= 0.6
    ]
    
    return person_names[:10]  # Top 10


# ===== EJEMPLO DE USO =====

if __name__ == "__main__":
    print("="*80)
    print("ğŸ‡ªğŸ‡¸ ANALIZADOR GRAMATICAL ESPAÃ‘OL")
    print("="*80)
    
    # Texto de prueba del "Collar de la Reina"
    test_text = """
    Dos o tres veces al aÃ±o, con motivo de solemnidades importantes,
    como los bailes de la embajada de Austria o las veladas de lady
    Billingstone, la condesa de Dreux-Soubise lucÃ­a sobre sus blancos
    hombros Â«el collar de la reinaÂ». Era, en efecto, el famoso collar,
    el legendario collar que BÃ¶hmer y Bassenge, joyeros de la corona,
    destinaban a la Du Barry, que el cardenal de Rohan-Soubise creyÃ³
    ofrecer a MarÃ­a Antonieta, reina de Francia.
    """
    
    analyzer = SpanishGrammarAnalyzer()
    entities = analyzer.extract_proper_nouns(test_text)
    
    print("\nâœ… NOMBRES PROPIOS EXTRAÃDOS:")
    print(f"{'Nombre':<30} {'Tipo':<15} {'Confianza':<12} {'Â¿Persona?':<10} {'GÃ©nero':<12}")
    print("-" * 80)
    
    for entity in entities:
        print(f"{entity.text:<30} {entity.word_type.value:<15} {entity.confidence:<12.0%} {str(entity.is_person):<10} {entity.gender or 'N/A':<12}")
    
    print(f"\nğŸ“Š Total extraÃ­do: {len(entities)} entidades")
    print(f"   - Personas: {sum(1 for e in entities if e.is_person)}")
    print(f"   - Otros: {sum(1 for e in entities if not e.is_person)}")
    
    # Ejemplo de anÃ¡lisis sujeto-predicado
    print("\n" + "="*80)
    print("ğŸ” ANÃLISIS SUJETO-PREDICADO")
    print("="*80)
    
    sentence = "La condesa de Dreux-Soubise lucÃ­a sobre sus blancos hombros el collar de la reina"
    analysis = analyzer.identify_subject_predicate(sentence)
    
    print(f"\nOraciÃ³n: {sentence}")
    print(f"   Sujeto:    {analysis['subject']}")
    print(f"   Verbo:     {analysis['verb']}")
    print(f"   Predicado: {analysis['predicate']}")
    
    print("\n" + "="*80)


# =============================================================================
# FUNCIÃ“N PRINCIPAL PARA CLASIFICACIÃ“N UNIVERSAL DE ENTIDADES
# =============================================================================

def get_entity_type(entity: str, context: str) -> EntityType:
    """
    Clasifica entidad en tipo UNIVERSAL basÃ¡ndose en contexto
    
    Funciona para CUALQUIER dominio (literatura, ciencia, tÃ©cnico, acadÃ©mico)
    
    Args:
        entity: Nombre de la entidad ("GarcÃ­a", "BRCA1", "QuickSort", "relatividad")
        context: OraciÃ³n o pÃ¡rrafo completo donde aparece la entidad
    
    Returns:
        EntityType: PERSON | CONCEPT | OBJECT | PROCESS | LOCATION | ORGANIZATION | UNKNOWN
    
    Ejemplos:
        >>> get_entity_type("GarcÃ­a", "el doctor GarcÃ­a estudiÃ³ medicina")
        EntityType.PERSON
        
        >>> get_entity_type("BRCA1", "la proteÃ­na BRCA1 regula el ciclo celular")
        EntityType.OBJECT
        
        >>> get_entity_type("QuickSort", "el algoritmo QuickSort ordena en O(n log n)")
        EntityType.PROCESS
        
        >>> get_entity_type("relatividad", "la teorÃ­a de la relatividad explica")
        EntityType.CONCEPT
    """
    context_lower = context.lower()
    entity_lower = entity.lower()
    
    # MÃ‰TODO 1: Buscar INDICADOR en contexto (mÃ¡xima confianza)
    # Ejemplo: "la proteÃ­na BRCA1" â†’ indicador "proteÃ­na" â†’ OBJECT
    for entity_type, indicators in UNIVERSAL_INDICATORS.items():
        for indicator in indicators:
            # PatrÃ³n: "indicador + entidad" o "entidad + indicador"
            pattern_before = rf'\b{re.escape(indicator)}\s+{re.escape(entity_lower)}'
            pattern_after = rf'\b{re.escape(entity_lower)}\s+{re.escape(indicator)}'
            
            if re.search(pattern_before, context_lower) or re.search(pattern_after, context_lower):
                return entity_type
    
    # MÃ‰TODO 2: Buscar VERBO de contexto (alta confianza)
    # Ejemplo: "BRCA1 regula el ciclo" â†’ verbo "regula" â†’ OBJECT
    for entity_type, verbs in CONTEXT_VERBS.items():
        for verb in verbs:
            # PatrÃ³n: "entidad + verbo" (sujeto-verbo)
            pattern_subject = rf'\b{re.escape(entity_lower)}\s+{verb}'
            # PatrÃ³n: "verbo + entidad" (menos comÃºn pero vÃ¡lido)
            pattern_object = rf'\b{verb}\s+(?:el|la|los|las|un|una)?\s*{re.escape(entity_lower)}'
            
            if re.search(pattern_subject, context_lower) or re.search(pattern_object, context_lower):
                return entity_type
    
    # MÃ‰TODO 3: HeurÃ­sticas por estructura y contexto
    entity_words = entity.split()
    
    # Si tiene â‰¥2 palabras capitalizadas y verbo de persona â†’ PERSON
    if len(entity_words) >= 2 and entity[0].isupper():
        person_verbs = CONTEXT_VERBS.get(EntityType.PERSON, set())
        if any(verb in context_lower for verb in person_verbs):
            return EntityType.PERSON
        
        # Si no tiene verbo de persona pero tiene "de" o "del" â†’ posiblemente LOCATION
        if 'de' in entity_words or 'del' in entity_words:
            return EntityType.LOCATION
    
    # Si contiene nÃºmeros/letras (ej: "BRCA1", "QuickSort") â†’ OBJECT o PROCESS
    if re.search(r'\d', entity) or re.search(r'[A-Z]{2,}', entity):
        # Si tiene verbo tÃ©cnico cerca â†’ PROCESS
        technical_verbs = {'implementa', 'ejecuta', 'calcula', 'procesa', 'ordena'}
        if any(verb in context_lower for verb in technical_verbs):
            return EntityType.PROCESS
        # Si no â†’ OBJECT
        return EntityType.OBJECT
    
    # Si tiene artÃ­culo determinado + sustantivo abstracto â†’ CONCEPT
    if re.search(rf'\b(?:el|la)\s+{re.escape(entity_lower)}\s+(?:de|del|que|es|consiste)', context_lower):
        return EntityType.CONCEPT
    
    # Si todo falla â†’ UNKNOWN
    return EntityType.UNKNOWN


# FunciÃ³n auxiliar para compatibilidad con cÃ³digo existente
def classify_entity(entity: str, context: str) -> str:
    """Wrapper que retorna string en lugar de enum (compatibilidad)"""
    entity_type = get_entity_type(entity, context)
    return entity_type.value

