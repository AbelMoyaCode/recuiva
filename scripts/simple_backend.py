#!/usr/bin/env python3
"""
Backend simplificado solo para validaci√≥n sem√°ntica
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import uvicorn
import numpy as np
from sentence_transformers import SentenceTransformer
import json
from pathlib import Path

# Crear aplicaci√≥n FastAPI
app = FastAPI(title="Recuiva Validation API", version="1.0.0")

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Cargar modelo globalmente
print("ü§ñ Cargando modelo Sentence Transformers...")
model = SentenceTransformer('all-MiniLM-L6-v2')
print("‚úÖ Modelo cargado exitosamente")

# Datos de muestra para validaci√≥n
SAMPLE_CHUNKS = [
    "Active Recall es una t√©cnica de estudio que consiste en intentar recordar informaci√≥n sin mirar el material. Es m√°s efectivo que la relectura pasiva porque fuerza al cerebro a recuperar activamente la informaci√≥n.",
    "La validaci√≥n sem√°ntica utiliza modelos de lenguaje como Sentence Transformers para comparar significados. Sentence Transformers convierte texto en vectores que representan el significado sem√°ntico.",
    "Los embeddings son representaciones vectoriales de texto que capturan el significado sem√°ntico. La similitud coseno entre embeddings indica qu√© tan similar es el significado de dos textos.",
    "El aprendizaje efectivo requiere pr√°ctica activa y recuperaci√≥n de informaci√≥n. Las t√©cnicas pasivas como releer son menos efectivas que las t√©cnicas activas como hacerse preguntas.",
    "La comprensi√≥n profunda se logra cuando el estudiante puede explicar conceptos con sus propias palabras y aplicarlos en nuevos contextos."
]

# Generar embeddings para los chunks de muestra
print("üìö Generando embeddings para material de muestra...")
sample_embeddings = model.encode(SAMPLE_CHUNKS)
print(f"‚úÖ {len(SAMPLE_CHUNKS)} embeddings generados")

class ValidationRequest(BaseModel):
    carpeta_id: str
    pregunta: str
    respuesta_usuario: str

class ValidationResult(BaseModel):
    score: float
    feedback: str
    relevant_chunks: List[dict] = []
    best_match_chunk: Optional[dict] = None

@app.get("/api/health")
async def health_check():
    return {
        "status": "healthy",
        "model_loaded": True,
        "chunks_available": len(SAMPLE_CHUNKS)
    }

@app.post("/api/validate-semantic", response_model=ValidationResult)
async def validate_semantic(request: ValidationRequest):
    """
    Validaci√≥n sem√°ntica simplificada
    """
    try:
        print(f"üîç Validando respuesta: {request.respuesta_usuario[:100]}...")
        
        # Generar embedding para la respuesta del usuario
        user_embedding = model.encode([request.respuesta_usuario])
        
        # Calcular similaridades
        similarities = []
        for i, chunk in enumerate(SAMPLE_CHUNKS):
            chunk_embedding = sample_embeddings[i:i+1]
            
            # Calcular similitud coseno
            cosine_sim = np.dot(user_embedding[0], chunk_embedding[0]) / (
                np.linalg.norm(user_embedding[0]) * np.linalg.norm(chunk_embedding[0])
            )
            
            similarities.append({
                "chunk_id": i,
                "text": chunk,
                "similarity": float(cosine_sim)
            })
        
        # Encontrar la mejor coincidencia
        best_match = max(similarities, key=lambda x: x["similarity"])
        score_percentage = int(best_match["similarity"] * 100)
        
        # Generar feedback
        if score_percentage >= 80:
            feedback = f"¬°Excelente! Tu respuesta demuestra comprensi√≥n profunda. Score: {score_percentage}%"
        elif score_percentage >= 60:
            feedback = f"Bien. Tu respuesta est√° correcta pero podr√≠as profundizar m√°s. Score: {score_percentage}%"
        elif score_percentage >= 40:
            feedback = f"Regular. Tu respuesta tiene relaci√≥n pero necesita m√°s precisi√≥n. Score: {score_percentage}%"
        else:
            feedback = f"Necesita mejorar. Revisa el material y vuelve a intentar. Score: {score_percentage}%"
        
        # Top 3 chunks m√°s relevantes
        relevant_chunks = sorted(similarities, key=lambda x: x["similarity"], reverse=True)[:3]
        
        result = ValidationResult(
            score=score_percentage,
            feedback=feedback,
            relevant_chunks=relevant_chunks,
            best_match_chunk=best_match
        )
        
        print(f"‚úÖ Validaci√≥n completada - Score: {score_percentage}%")
        return result
        
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error: {str(e)}")

if __name__ == "__main__":
    print("üöÄ Iniciando servidor de validaci√≥n...")
    uvicorn.run(app, host="127.0.0.1", port=8002)