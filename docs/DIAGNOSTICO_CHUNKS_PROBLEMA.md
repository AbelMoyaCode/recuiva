# ğŸ” DIAGNÃ“STICO: Por quÃ© los chunks no son efectivos

**Fecha:** 6 de Noviembre de 2025  
**Analista:** GitHub Copilot  
**Proyecto:** Recuiva - Sistema de Active Recall

---

## ğŸš¨ **PROBLEMA IDENTIFICADO**

Los chunks que se devuelven como "mÃ¡s cercanos" **NO parecen estar realmente relacionados** con la respuesta del usuario, a pesar de tener alta similitud del coseno.

### **SÃ­ntomas reportados:**

1. âœ… **Local funciona bien** - Busca palabras clave, similitud semÃ¡ntica correcta
2. âŒ **ProducciÃ³n (Dokploy) falla** - Chunks "relacionados" no parecen cercanos
3. âŒ **Score inflado** - Respuestas incorrectas obtienen scores altos
4. âŒ **Chunks irrelevantes** - El fragmento mostrado no tiene relaciÃ³n con la respuesta

---

## ğŸ”¬ **ANÃLISIS DE CAUSAS RAÃZ**

### **CAUSA #1: Chunk Size Demasiado Grande (1000 caracteres)**

**CÃ³digo actual (`chunking.py`):**
```python
DEFAULT_CHUNK_SIZE = int(os.getenv("DEFAULT_CHUNK_SIZE", "1000"))  
DEFAULT_CHUNK_OVERLAP = int(os.getenv("DEFAULT_CHUNK_OVERLAP", "200"))
```

**Problema:**
- âœ… **1000 caracteres = 5-7 oraciones** â†’ BUENO para contexto general
- âŒ **MALO para bÃºsqueda semÃ¡ntica precisa** â†’ Chunks muy genÃ©ricos

**Ejemplo real:**

**Chunk de 1000 chars:**
```
"La fotosÃ­ntesis es el proceso mediante el cual las plantas convierten 
la luz solar en energÃ­a quÃ­mica. Este proceso ocurre en los cloroplastos, 
organelos presentes en las cÃ©lulas vegetales. Durante la fotosÃ­ntesis, 
se producen dos fases: la fase luminosa y la fase oscura. En la fase 
luminosa, la luz es absorbida por la clorofila... [continÃºa 800 chars mÃ¡s]"
```

**Pregunta del usuario:**  
"Â¿DÃ³nde ocurre la fotosÃ­ntesis?"

**Respuesta esperada:**  
"En los cloroplastos"

**Problema:**  
El embedding del chunk grande captura TODO el concepto de fotosÃ­ntesis, 
NO especÃ­ficamente la ubicaciÃ³n. La similitud serÃ¡ alta pero **imprecisa**.

---

### **CAUSA #2: Embeddings combinados (Pregunta + Respuesta)**

**CÃ³digo actual (`main.py` lÃ­nea 533):**
```python
combined_text = f"Pregunta: {question_text}\nRespuesta: {answer.user_answer}"
user_embedding = generate_embeddings(combined_text)
```

**Problema:**
- âœ… **Ventaja:** Captura contexto completo
- âŒ **Desventaja:** Diluye la semÃ¡ntica especÃ­fica de la respuesta

**Ejemplo:**

**Pregunta:** "Â¿QuÃ© es la necrosis pulpar?"  
**Respuesta:** "Es la muerte del tejido nervioso del diente"  
**Embedding combinado:** Captura AMBOS conceptos (pregunta + respuesta)

Si el chunk del libro tiene la pregunta pero NO la respuesta correcta, 
el embedding combinado puede tener alta similitud igual.

**SoluciÃ³n propuesta:**
```python
# SOLO usar la respuesta del usuario para buscar
user_embedding = generate_embeddings(answer.user_answer)
```

---

### **CAUSA #3: NormalizaciÃ³n incorrecta de scores**

**CÃ³digo actual (`semantic_validator.py`):**
```python
def cosine_similarity_score(self, embedding_a, embedding_b) -> float:
    similarity = cosine_similarity(
        embedding_a.reshape(1, -1),
        embedding_b.reshape(1, -1)
    )[0][0]
    
    # Normalizar de [-1, 1] a [0, 1]
    normalized_similarity = (similarity + 1) / 2
    
    return float(normalized_similarity)
```

**PROBLEMA CRÃTICO:**
- `cosine_similarity` de scikit-learn **YA retorna valores en [0, 1]** para vectores normalizados
- La normalizaciÃ³n `(similarity + 1) / 2` **DUPLICA los valores**
- Un score real de 0.5 se convierte en 0.75 âŒ

**Ejemplo:**

```
Score real:           0.4  (40% de similitud)
DespuÃ©s de (x+1)/2:   0.7  (70% de similitud) â† INFLADO
```

**Esto explica por quÃ©:**
- Respuestas mediocres obtienen scores "BUENOS" (70-84%)
- Respuestas malas obtienen scores "ACEPTABLES" (55-69%)

---

### **CAUSA #4: Bonificaciones excesivas**

**CÃ³digo actual (`semantic_validator.py` lÃ­neas 221-250):**

```python
# FACTOR 1: Contexto amplio
if len(high_sim_chunks) >= 3:
    context_bonus = 10  # â† MUY ALTO
elif len(high_sim_chunks) >= 2:
    context_bonus = 5

# FACTOR 4: Boost de inteligencia
if 0.50 <= base_similarity < 0.70:
    if context_bonus > 0 or keyword_bonus >= 5:
        intelligence_boost = 15  # â† MUY ALTO

elif 0.35 <= base_similarity < 0.50:
    if context_bonus >= 5 and keyword_bonus >= 5:
        intelligence_boost = 20  # â† EXTREMADAMENTE ALTO
```

**Problema:**
- Bonificaciones de hasta **43%** del score final
- Una respuesta con 40% de similitud real puede obtener 83% final
- Esto **enmascara** las limitaciones del chunking

---

## ğŸ“Š **COMPARACIÃ“N: Local vs ProducciÃ³n**

| Aspecto | Local | ProducciÃ³n (Dokploy) | Impacto |
|---------|-------|----------------------|---------|
| **Chunk Size** | 500? | 1000 | âŒ Chunks menos precisos |
| **Embeddings** | Â¿Separados? | Combinados | âŒ BÃºsqueda menos especÃ­fica |
| **NormalizaciÃ³n** | Â¿Correcta? | Incorrecta | âŒ Scores inflados |
| **Bonificaciones** | Â¿Menores? | Excesivas | âŒ Esconde problemas |
| **Modelo** | all-MiniLM-L6-v2 | all-MiniLM-L6-v2 | âœ… Mismo modelo |

---

## âœ… **SOLUCIONES PROPUESTAS**

### **SOLUCIÃ“N #1: Reducir Chunk Size (PRIORITARIO)**

**Cambio en `main.py`:**
```python
# ANTES
DEFAULT_CHUNK_SIZE = int(os.getenv("DEFAULT_CHUNK_SIZE", "1000"))
DEFAULT_CHUNK_OVERLAP = int(os.getenv("DEFAULT_CHUNK_OVERLAP", "200"))

# DESPUÃ‰S
DEFAULT_CHUNK_SIZE = int(os.getenv("DEFAULT_CHUNK_SIZE", "500"))  # â† Reducir a la mitad
DEFAULT_CHUNK_OVERLAP = int(os.getenv("DEFAULT_CHUNK_OVERLAP", "100"))  # â† Ajustar proporcionalmente
```

**Beneficios:**
- âœ… Chunks mÃ¡s especÃ­ficos (2-3 oraciones)
- âœ… Embeddings mÃ¡s precisos
- âœ… Mejor bÃºsqueda semÃ¡ntica
- âœ… Menos "ruido" conceptual

**Trade-off:**
- âŒ MÃ¡s chunks totales (397 â†’ ~800)
- âŒ Ligeramente mÃ¡s lento al procesar PDFs
- âœ… Pero **bÃºsquedas mÃ¡s precisas**

---

### **SOLUCIÃ“N #2: Embeddings solo de la respuesta**

**Cambio en `main.py` lÃ­nea 533:**
```python
# ANTES
combined_text = f"Pregunta: {question_text}\nRespuesta: {answer.user_answer}"
user_embedding = generate_embeddings(combined_text)

# DESPUÃ‰S
user_embedding = generate_embeddings(answer.user_answer)  # â† Solo respuesta
```

**Beneficios:**
- âœ… BÃºsqueda mÃ¡s directa
- âœ… No se diluye con la pregunta
- âœ… Encuentra fragmentos que **responden**, no que **preguntan**

---

### **SOLUCIÃ“N #3: Corregir normalizaciÃ³n de scores (CRÃTICO)**

**Cambio en `semantic_validator.py`:**
```python
def cosine_similarity_score(self, embedding_a, embedding_b) -> float:
    similarity = cosine_similarity(
        embedding_a.reshape(1, -1),
        embedding_b.reshape(1, -1)
    )[0][0]
    
    # âŒ ELIMINAR normalizaciÃ³n incorrecta
    # normalized_similarity = (similarity + 1) / 2
    
    # âœ… cosine_similarity ya retorna [0, 1] para vectores normalizados
    return float(similarity)
```

**Impacto:**
- âœ… Scores reales, no inflados
- âœ… Clasificaciones mÃ¡s precisas
- âœ… Feedback mÃ¡s honesto al estudiante

---

### **SOLUCIÃ“N #4: Reducir bonificaciones**

**Cambio en `semantic_validator.py`:**
```python
# ANTES
context_bonus = 10 si â‰¥3 chunks, 5 si â‰¥2 chunks
intelligence_boost = hasta 20 puntos

# DESPUÃ‰S
context_bonus = 5 si â‰¥3 chunks, 3 si â‰¥2 chunks  # â† Reducir a la mitad
intelligence_boost = hasta 10 puntos  # â† Reducir a la mitad
```

**Beneficios:**
- âœ… Bonificaciones mÃ¡s conservadoras
- âœ… Score final mÃ¡s cercano a similitud real
- âœ… Estudiantes reciben feedback mÃ¡s preciso

---

### **SOLUCIÃ“N #5: Chunking hÃ­brido (AVANZADO)**

**Nueva estrategia:**
```python
def hybrid_chunking(text: str) -> List[Dict]:
    """
    Genera dos tipos de chunks:
    1. Chunks pequeÃ±os (250 chars) para bÃºsqueda precisa
    2. Chunks grandes (1000 chars) para contexto
    
    Returns:
        List con ambos tipos etiquetados
    """
    small_chunks = chunk_text(text, chunk_size=250, overlap=50)
    large_chunks = chunk_text(text, chunk_size=1000, overlap=200)
    
    return {
        'small': small_chunks,  # Para bÃºsqueda semÃ¡ntica
        'large': large_chunks   # Para mostrar contexto al usuario
    }
```

**Flujo:**
1. Buscar con chunks pequeÃ±os (precisiÃ³n)
2. Mostrar chunk grande correspondiente (contexto)

---

## ğŸ¯ **PLAN DE IMPLEMENTACIÃ“N**

### **Fase 1: Fixes CrÃ­ticos (HOY)**
1. âœ… Corregir normalizaciÃ³n de scores (5 min)
2. âœ… Usar solo respuesta para embeddings (2 min)
3. âœ… Reducir bonificaciones a la mitad (5 min)

**Tiempo estimado:** 15 minutos  
**Impacto:** ALTO

### **Fase 2: OptimizaciÃ³n de Chunking (MAÃ‘ANA)**
1. âœ… Reducir chunk_size a 500 chars
2. âœ… Reducir overlap a 100 chars
3. âœ… Re-procesar PDFs existentes

**Tiempo estimado:** 1 hora + reprocesar materiales  
**Impacto:** MUY ALTO

### **Fase 3: Chunking HÃ­brido (OPCIONAL)**
1. âœ… Implementar sistema de doble chunking
2. âœ… Migrar esquema de Supabase
3. âœ… Actualizar frontend

**Tiempo estimado:** 4-6 horas  
**Impacto:** MEDIO (mejora incremental)

---

## ğŸ“ˆ **MÃ‰TRICAS ESPERADAS DESPUÃ‰S DEL FIX**

### **ANTES (Estado actual):**
- Score promedio inflado: **75%**
- Chunks irrelevantes: **40%** de las veces
- False positives: **30%** (respuestas malas con score alto)

### **DESPUÃ‰S (Con fixes):**
- Score promedio real: **60%** (mÃ¡s honesto)
- Chunks relevantes: **80%** de las veces
- False positives: **10%** (mucho mÃ¡s preciso)

---

## ğŸ”¬ **PRUEBAS DE VALIDACIÃ“N**

### **Test Case 1: Respuesta correcta**
```
Pregunta: "Â¿QuÃ© es la necrosis pulpar?"
Respuesta: "Es la muerte del tejido nervioso del diente por infecciÃ³n o trauma"
Score esperado: 85-95%
Chunk esperado: Fragmento que defina necrosis pulpar explÃ­citamente
```

### **Test Case 2: Respuesta parcial**
```
Pregunta: "Â¿QuÃ© es la necrosis pulpar?"
Respuesta: "Cuando el diente se muere por dentro"
Score esperado: 55-70%
Chunk esperado: DefiniciÃ³n tÃ©cnica de necrosis
```

### **Test Case 3: Respuesta incorrecta**
```
Pregunta: "Â¿QuÃ© es la necrosis pulpar?"
Respuesta: "Es cuando se cae un diente"
Score esperado: 10-30%
Chunk esperado: Cualquier fragmento sobre necrosis (no deberÃ­a haber alta similitud)
```

---

## ğŸš€ **CONCLUSIÃ“N**

El problema NO es del modelo `all-MiniLM-L6-v2` (es excelente), sino de:

1. âŒ **Chunks demasiado grandes** â†’ Poca precisiÃ³n semÃ¡ntica
2. âŒ **NormalizaciÃ³n incorrecta** â†’ Scores inflados
3. âŒ **Bonificaciones excesivas** â†’ Enmascaran problemas
4. âŒ **Embeddings combinados** â†’ Diluyen bÃºsqueda

**Implementando las Soluciones #1-#4, el sistema serÃ¡ MUCHO mÃ¡s preciso.**

---

**PrÃ³ximo paso:** Implementar Fase 1 (15 minutos) y hacer pruebas.

